[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Global Health Research Methods",
    "section": "",
    "text": "This book is in the process of being updated. Chapters will be released on a rolling basis. This work is shared under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "ghr.html#what-is-global-health",
    "href": "ghr.html#what-is-global-health",
    "title": "1  Global Health Research",
    "section": "1.1 What is Global Health?",
    "text": "1.1 What is Global Health?\nNew York County Courthouse, Lower Manhattan, New York City, circa 2009\nJudge presiding over jury selection: And what do you do, Mr. Green?\nMe: Global health research.\nJudge:\nMe: I study access to mental health services.\nJudge: So health policy then?\nMe: No, mostly intervention research.\nJudge: Globally.\nMe: No, not quite.\nJudge: What is global health, Mr. Green?\nMe: Well, you see…rambles…\nJudge: Thank you, Mr. Green. You are dismissed.\nI’ve had this conversation hundreds of times since that court appearance. Now when asked, I say something like, “global health takes a global perspective on public health problems,” drawing inspiration from Skolnik (2019). In the wake of the pandemic, I find that people nod along at this framing. It makes sense to them. Thanks, COVID-19!\n\nSkolnik, R. (2019). Global health 101, fourth edition. Jones & Bartlett Learning.\n\nMerson, M. H. et al. (2018). Global health: Diseases, programs, systems, and policies (4th ed.). Jones & Bartlett Learning.\n\nKoplan, J. P. et al. (2009). Towards a common definition of global health. The Lancet, 373(9679), 1993–1995.\nGo any deeper below the ontological surface, however, and you’ll find that there is not a consensus definition of global health (Merson et al., 2018). We’ll adopt this one from Koplan et al. (2009):\n\nGlobal health is an area for study, research, and practice that places a priority on improving health and achieving equity in health for all people worldwide. Global health emphasizes transnational health issues, determinants, and solutions; involves many disciplines within and beyond the health sciences and promotes interdisciplinary collaboration; and is a synthesis of population-based prevention with individual-level clinical care.\n\nTake note of two key elements of their definition:\n\nit includes scholars, researchers, and practitioners working across disciplinary boundaries; and\nit goes beyond simply improving health to include the goal of achieving health equity.\n\nTo expand on the first point, this definition reflects the reality that global health challenges are complex, so the search for solutions must span disciplines. In the study of malaria, for example, you can read about the spread of the disease (epidemiology), the impact of illness on future productivity (economics), the merits of free or subsidized bed nets (public policy), mosquito habitats (ecology), the efficacy of vaccines to prevent the disease (medicine and statistics), rapid diagnostic tests (biomedical engineering), and the adoption and use of bed nets (psychology), just to name a few areas of inquiry.\nThe second point is that global health is action-oriented, seeking to achieve health equity for all people worldwide. The WHO (2021) defines equity as follows:\n\nWHO. (2021). Health Equity.\n\nEquity is the absence of unfair, avoidable or remediable differences among groups of people, whether those groups are defined socially, economically, demographically, or geographically or by other dimensions of inequality (e.g. sex, gender, ethnicity, disability, or sexual orientation). Health is a fundamental human right. Health equity is achieved when everyone can attain their full potential for health and well-being.\n\nPut another way, health inequities are unfair and unjust differences in healthcare access or health outcomes that can be prevented or fixed. Health inequities are structural, often resulting from decisions we make about who gets access to resources.\nThe consequence of inequity is often inequality. For instance, inequitable access to healthcare services can lead to unequal health outcomes—health inequalities—between groups. Differences in health status are also referred to as health disparities.\nThe COVID-19 pandemic has given us many examples of health inequities and disparities. For instance, data compiled by the website Health Inequities Tracker, visualized in Figure 1.1, show that through at least August 2021, Hispanics and Latinos in the United States were over-represented in COVID-19 hospitalizations, while non-Hispanic Whites were substantially under-represented (Satcher Health Leadership Institute, 2021).\n\nSatcher Health Leadership Institute. (2021). Health Equity Tracker.\n\n\n\n\nFigure 1.1: COVID-19 health disparities.\n\n\n\nMacias Gil et al. (2020) point to several factors that might help to explain why Latinos and Hispanics were disproportionately affected by COVID-19:\n\nMacias Gil, R. et al. (2020). COVID-19 pandemic: Disparate health impact on the hispanic/latinx population in the united states. The Journal of Infectious Diseases, 222(10), 1592–1595.\n\nHigher rates of co-morbid health conditions\nMore likely to be underinsured or uninsured\nUndocumented immigration status\nLanguage barriers to accessing services\nOverrepresentation in “essential” jobs where working from home was not possible\nGreater financial pressures to show up to work, even if unwell or potentially exposed to the virus\nMore likely to live in multigenerational homes where transmission was more likely\n\nSeveral of these underlying factors, such as undocumented immigration status, fall into the category of social determinants of health (WHO, 2013).\n\nWHO. (2013). Social determinants of health: Key concepts.\n\nThe circumstances in which people are born, grow up, live, work and age, and the systems put in place to deal with illness.\n\nConsider the directed acyclic graph, or DAG, in Figure 1.2 that illustrates how social determinants of health might have influenced the pandemic. I’ll introduce DAGs in more detail in a later chapter, so for now think of this as a (simplified) hypothesized conceptual model of what precipitates COVID-19 infection and hospitalization.\n\n\n\n\nFigure 1.2: Based on Nafilyan et al. (2021).\nNafilyan, V. et al. (2021). Occupation and COVID-19 mortality in England: A national linked data study of 14.3 million adults. medRxiv.\n\n\n\n\nAs represented in this DAG, hospitalization with COVID-19 is directly caused by infection with the novel coronavirus, SARS-CoV-2, but who gets infected is not completely random. Infectious diseases are social affairs, and some people are more vulnerable because of their context. For instance, vaccinated individuals are less likely to get infected, and vaccination rates are highest in the U.S. among the most educated. Looking further back in the causal chain, educational attainment is highest among groups without historical social inequities such as systematic racism.\nA diagram like this suggests that to prevent future pandemics we need to gain a deeper understanding of the interaction between social determinants of health and disease risk. More importantly, it implies that we have work to do to fix the underlying societal inequities that make certain groups more vulnerable. As we’ve seen with COVID-19, technological solutions alone—like developing a vaccine in record time—may not be sufficient.\n\n\n\n\n\nFigure 1.3: Global access to COVID-19 vaccines.\n\n\n\nSirleaf, E. J. et al. (2021). Achieving vaccination justice: A call for global cooperation. PLOS Global Public Health, 1(10), 1–3.\nAnother example of a COVID-19 inequity is global access to vaccines (see Figure 1.2). By October 2021, nearly half of the world’s population had received at least one dose of a COVID-19 vaccine, but the first 6.5 billion doses mostly went into the arms of citizens of wealthy countries. Less than 3 percent of people in low-income countries had received even one dose. While true that many low-income countries escaped the worst of the pandemic’s first few waves, the glacial roll out of vaccines globally—what some have decried as a vaccine apartheid—leaves many nations vulnerable to deadly new variants. This puts everyone at risk. Ellen Johnson Sirleaf and Helen Clark, the former heads of Liberia and New Zealand, respectively, state this plainly in the inaugural issue of PLOS Global Public Health (Sirleaf et al., 2021):\n\nAchieving vaccination justice is the first great test of this pandemic era—it requires targets and aspirations for vaccine access to be determined by health criteria not a country’s economic status, and timely delivery not a two-speed world where high-income populations are fully immunized within months but the poor are denied access for years. Meeting the vaccine justice test will signal that we have both understood the interdependence that determines our planetary future and have the capacity to act on it. Failing the test will condemn us to a ‘forever crisis’ of insecurity and recrimination as virus variants are given free rein and new vaccines struggle to keep up."
  },
  {
    "objectID": "ghr.html#what-is-research",
    "href": "ghr.html#what-is-research",
    "title": "1  Global Health Research",
    "section": "1.2 What is Research?",
    "text": "1.2 What is Research?\n\n\n\nThis definition comes from Title 45 of the United States Code of Federal Regulations, Part 46, Subpart A, also known as the Common Rule.\n\nResearch is a systematic investigation designed to develop or contribute to generalizable knowledge. Let’s break down this definition.\n\nResearch is systematic in that it follows a documented and repeatable methodology.\nInvestigations include research development, testing, and evaluation.\nBy generalizable knowledge, we mean that the investigation intends to advance our scientific understanding. The goal is to go beyond the collection of facts about a particular sample and make conclusions that have relevance for other scholars, practitioners, or policymakers.\n\nFor instance, you might interview parents of young children about their use of mosquito nets. You intend to analyze the transcripts and develop new ideas about the barriers to bed net use that you hope to publish in an academic journal. Other scholars will read this work use it to develop new theories of health behavior and create new interventions that promote bed net use. This is research.\nBut what if a journalist wants to write a feature article about the burden of malaria and interviews a few of the same parents? Is this research?\n\n\nThe Common Rule definition of research excludes journalism activities, public health surveillance activities in support of an order from a public health agency, criminal justice investigations, and operational activities related to national security.\nNo.\nFor one, the journalist might not follow a systematic method for deciding which parents to approach, how to conduct the interviews, or how to synthesize what they learn. Second, the journalist has a different objective. Whereas you wanted to systematically advance our understanding of barriers to bed net use—insights that might apply to different parents in other settings—the journalist intends to inform the public by telling the stories of a few specific parents.\nAnother way that a study can advance scientific understanding is by developing and testing scientific methods and procedures. For instance, a research team might plan a small pilot test to collect initial data that will inform the design of a larger study. In most cases, we’d consider these pre-study activities to be research—even if the team does not intend to publish the results—because the pilot study is part of the knowledge generation process.\nBut here again, intent matters. Let’s say Facebook randomly assigns a small percentage of its users to receive email campaign A or campaign B and tracks which campaign generates the most clicks or sales. The company’s objective in this case is to determine which campaign optimizes their marketing spend for conversions, not to say something more general about human perception and behavior. Therefore, it’s not considered research.\nAs we’ll discuss in a later chapter, it’s always a good idea to consult with an Institutional Review Board to determine if your proposed work is considered research (and if it is, whether it falls under policies requiring ethical review)."
  },
  {
    "objectID": "ghr.html#what-makes-research-scientific",
    "href": "ghr.html#what-makes-research-scientific",
    "title": "1  Global Health Research",
    "section": "1.3 What Makes Research Scientific?",
    "text": "1.3 What Makes Research Scientific?\nWhether you’re designing a study that relies on qualitative methods, quantitative methods, or a blend of both, there are several main characteristics of scientific research that apply to global health (King et al., 2021; Leary, 2012):\n\nKing, G. et al. (2021). Designing Social Inquiry: Scientific Inference in Qualitative Research, New Edition. Princeton University Press.\n\nLeary, M. (2012). Introduction to behavioral research methods (6th ed.). Pearson.\n\nthe approach is empirical;\nthe procedures are public;\nthe goal is inference; and\nthe conclusions are uncertain.\n\n\nTHE APPROACH IS EMPIRICAL\n\n\nPeople often ask me questions that, at least in theory, can be answered with data, but I don’t know the answers. In these situations, I like to remove my glasses, stare into middle distance, and say, “That’s an interesting empirical question”. It means, “I don’t know. We should collect some data.”\nScience is built on systematic data collection. That’s what makes it an empirical endeavor. Expert opinion is a form of evidence, but it’s not empirical evidence. Empirical evidence comes from systematic observation, and the method of observation can be quantitative or qualitative. Contrary to what some people believe, empirical is not a synonym for quantitative.\n\n\nTHE PROCEDURES ARE PUBLIC\n\n\n\n\n\n\nA poorly documented Method section. Source: Internet meme, unknown author.\n\n\n\nScientific research uses public methods that can be examined and replicated. A Method section in a scientific paper is like a recipe. If you’ve ever tried to follow a confusing recipe, you can appreciate the importance of good documentation. Your study’s recipe must be clear (well written), thorough (no ‘dash’ of this or that), and shared publicly (not a secret passed down to lab members).\nWe care about complete and transparent reporting in science for several reasons. First, as consumers of research, we rely on authors’ descriptions of their empirical methods to come to our own conclusions about the findings. If research colleagues cannot inspect your methods, they will have little reason to trust your results. Second, no one study should ever rule the day. If the results of your study are robust, another research group should be able to follow the recipe and replicate the findings. When such findings are replicated, we all have more confidence in the results. Third, sharing your methods makes scientific progress possible.\n\n\nTHE GOAL IS INFERENCE\nEmpiricism is essential to science, but science is more than observation. To create generalizable knowledge, you need data and inference. There are two broad categories of inference: (a) descriptive inference and (b) causal inference.\nDescriptive inference is using the data we observe to make conclusions about that which we don’t or can’t observe directly. For instance, you might survey 200 people about their health beliefs, but your real aim is to make conclusions about the broader group. You use the data you have from 200 people to make this inference.\nCausal inference involves a different mental leap where we ask “what if” to make conclusions about causes and effects. Consider the case where we want to know which pill works better to resolve an illness, the red one or the blue one. The fundamental challenge to getting an answer is that we can’t give someone both pills simultaneously. An individual can only take one pill at a time. In this situation we might be able to randomly assign people to each type of pill as a tool for making a causal inference. But frequently, random assignment isn’t possible and we have to use other strategies for asking “what if”.\n\n\nTHE CONCLUSIONS ARE UNCERTAIN\nEvery method has limitations, every measurement has error, and every model is wrong to some extent. Take the estimation of maternal mortality rates as an example. Hogan published estimates for 181 countries (Hogan et al., 2010). Some countries, such as the United States, have vast amounts of data in vital registries that attempt to track all births and deaths. It’s not perfect, so we still estimate the maternal mortality rate using a statistical model.\n\nHogan, M. C. et al. (2010). Maternal mortality for 181 countries, 1980–2008: A systematic analysis of progress towards millennium development goal 5. The Lancet, 375(9726), 1609–1623.\n\n\n\nThis is still several hundred mostly preventable deaths per year. Currently in the U.S., the rate of maternal mortality among non-hispanic Black women is at least 2.5 times higher than the rate for non-hispanic White women.\n\nAs you can see in the left panel of Figure 1.4, the United States has a (relatively) low level of maternal mortality, between about 10-20 maternal deaths for every 100,000 live child births. Compared to some countries, the US has a lot of data points for estimating the level and trend in maternal deaths, so the uncertainty band is narrow.\n\n\n\n\nFigure 1.4: Estimates of the maternal mortality rate in the United States and Afghanistan.\n\n\n\nNow take a look at Afghanistan on the right. Note that the y-axis scale is much larger in the 1000s, reflecting the fact that many more Afghan women die of causes related to pregnancy or childbirth. Next, pay attention to the width of the uncertainty band. It spans a range of more than 3000 deaths. Compare this to a range of fewer than 5 deaths in the US! This is because there are very few data points available to estimate the ‘true’ value in Afghanistan, and these individual data points can differ by more than 1000 deaths.\nThe takeaway message is that there is uncertainty in everything. No single estimate can be considered the answer. Embrace uncertainty and you will become a better scientist."
  },
  {
    "objectID": "ghr.html#what-constitutes-global-health-research",
    "href": "ghr.html#what-constitutes-global-health-research",
    "title": "1  Global Health Research",
    "section": "1.4 What Constitutes Global Health Research?",
    "text": "1.4 What Constitutes Global Health Research?\nGlobal health research brings together scholars and practitioners from many different disciplines to tackle big challenges. Therefore, the methods of these disciplines are the methods of global health research. We can organize the research landscape as shown in Figure 1.8.\n\n\n\n\nFigure 1.5: A research taxonomy.\n\n\n\nResearch is divided into two main categories: basic and applied. Overlapping with applied research is an area of work called “monitoring and evaluation”, or M&E. Let’s examine what constitutes research before turning to M&E.\n\nBASIC RESEARCH\n\n\nBasic research is sometimes referred to as the ‘bench’ in the ‘bench to bedside’ cascade of research needed to take an idea from the lab to a new medical treatment. This is accurate but incomplete. Fields like psychology also conduct basic research into constructs like emotion and violence that seek to expand our understanding. This is not ‘bench science’ as typically imagined, but it’s basic research nonetheless.\nBasic research—also known as “pure” or “blue skies” research—is the pursuit of fundamental knowledge of phenomena. For example, scientists conduct laboratory experiments to understand the parasitic life cycle and how parasites interact with humans at different stages. Another example is the scientific investigation of the properties of cancer cells to better understand how they grow and spread.\nThe information generated by basic science becomes the basis for applied science. Harvard neurobiologist Dr. Rachel Wilson explains this beautifully:\n\n\n\n\n\nWatch Dr. Wilson’s full remarks.\n\n\nThe new therapies of today were the prototypes of yesterday. And the prototypes of yesterday were previously just findings in laboratories, and before that they were just an idea. Unless we have new ideas, we’re not going to have useful therapies. Great new therapies don’t just fall like apples from a tree.\n\n\n\nAPPLIED RESEARCH\nApplied research focuses on specific problems or real-world applications. Much of global health research falls into the applied domain because our mission is to improve health and achieve equity in health for all people worldwide.\n\nClinical Research\nApplied science takes many different forms, including clinical research. Clinical research is a broad field that aims to understand human disease, develop better ways to detect, diagnose, prevent, and treat disease, and to promote health (Roundtable et al., 2002). Table 1.1 lists several domains of clinical research.\n\nRoundtable, I. of M. (US). C. R. et al. (2002). Definitions of Clinical Research and Components of the Enterprise. National Academies Press (US).\n\n\n\n\n\nTable 1.1:  Different types of clinical research \n \n  \n    Domain \n    Description \n  \n \n\n  \n    Treatment/prevention research \n    Test new approaches for preventing or treating illness; includes clinical trials of drugs, biologics, devices, instruments, and behavioral interventions \n  \n  \n    Screening research \n    Develop and evaluate methods for detecting illness risk factors or markers \n  \n  \n    Diagnostic research \n    Develop and evaluate methods for identifying health conditions or illness \n  \n  \n    Genetic studies \n    Examine links between genes and disorders \n  \n  \n    Epidemiological studies \n    Study the patterns, causes, prevalence, and incidence of disease in a population \n  \n  \n    Health services research \n    Study how people access healthcare services, healthcare costs, and outcomes; operations research \n  \n\n\n\n\n\n\n\n\n\n\n\n\nThese phases are broadly similar across different regulatory bodies around the world, including the U.S. Federal Drug Administration (FDA), the European Medicines Agency (EMA), the Central Drugs Standard Control Organization in India, and the National Medical Products Administration in China, among many others. Here’s a brief overview of the phases from the NIH’s National Cancer Institute.\n\nOne type of clinical research is a clinical trial. Table 1.2 lists the phases of trials that drugs, biologics, devices, and instruments complete prior to going to market. In the early phases of drug trials, the objective is to understand how the compound affects the body. What is a safe dose that could be effective? Phase 3 trials put the optimal dose to the test, seeking to determine if the drug “works” and to quantify the size of the effect. Drugs that pass this test are typically approved for use by the governing regulatory body. Once a drug reaches market, Phase 4 trials monitor side effects and efficacy over time.\n\n\n\n\n\nTable 1.2:  Clinical trial phases \n \n  \n    Phase \n    Enrollment \n    Goal \n  \n \n\n  \n    Preclinical research \n     \n    Are there signs that the drug candidate will have an effect in the lab? \n  \n  \n    0 \n    <10 \n    What happens in the body (pharmacokinetics) when a very low dose is administered to human subjects? (optional phase) \n  \n  \n    1 \n    10s \n    Is the drug safe? What is the best dose that balances possible effects with toxicity? \n  \n  \n    2 \n    100s \n    When using this optimal dose, is there any effect of the drug on clinical markers or health outcomes? \n  \n  \n    3 \n    1000s \n    What is the effect of the drug on clinical markers or health outcomes when compared to an existing treatment or placebo in a randomized evaluation? Success at this stage is required for regulatory approval in some countries. \n  \n  \n    4 \n     \n    Are there long-term adverse effects of the drug once it is available on the market? \n  \n\n\n\n\n\n\n\n\n\nClick here to see a list of international trial registries.\n\nIn the United States, the FDA requires that most interventional studies of any regulated products with research sites in the U.S. be registered in the ClinicalTrials.gov trial registry (Food and Drug Administration Amendments Act of 2007, n.d.). Many countries have their own registries, and the World Health Organization maintains a web portal that searches across registries.\n\nFood and Drug Administration Amendments Act of 2007. (n.d.). Pub. L. No. 110-85, 121 Stat. 904 (2007).\n\n\n\nClick here to read about Aunt Debbie’s experience in a Phase 1 poliovirus trial at Duke University.\n\nTrial registries are useful for researchers and patients alike. When my wife’s Aunt Debbie learned she had an aggressive brain tumor, we searched ClinicalTrials.gov and identified several trials recruiting patients for experimental glioblastoma treatments. Debbie decided to take part in a Phase 1 trial that injected modified poliovirus into her tumor. She lived for another five years and helped to advance the science of glioblastoma treatment.\nHealthy volunteers and patients like Debbie are the backbone of clinical research. Their sacrifices, combined with the ingenuity of scientists and research teams, have created thousands of medical breakthroughs. But for every new drug approved, there is a trail of failure (see Figure 1.6). Recent studies estimate that fewer than 15% of candidates entering Phase 1 trials are ultimately approved by the FDA (Wong et al., 2019).\n\nWong, C. H. et al. (2019). Estimation of clinical trial success rates and related parameters. Biostatistics, 20(2), 273–286.\n\n\n\n\nFigure 1.6: Pipeline from basic research to FDA approval.\n\n\n\nThis pipeline does not include studies of behavioral interventions, social programs, or policies because the FDA only regulates drugs, biologics, devices, and instruments. Nevertheless, we still design studies to estimate the efficacy of interventions, programs, and policies, and many of these tests meet the World Health Organization’s definition of a ‘clinical trial’ (WHO, 2020):\n\nWHO. (2020). Clinical trials.\n\nThe International Committee of Medical Journal Editors adopted this definition in 2007 and recommended that all clinical trials should be registered in an appropriate trial registry. Many peer-reviewed health journals follow this guidance and will not accept manuscripts from unregistered studies.\n\n\nany research study that prospectively assigns human participants or groups of humans to one or more health-related interventions to evaluate the effects on health outcomes. (World Health Organization definition)\n\n\n\n\n\n\n\nDr. Pedro Alonso from the World Health Organization explains why this vaccine is a breakthrough in the prevention of malaria.\n\n\n\n\n\n\n\n\n\n\n\nCASE STUDY: Developing the first malaria vaccine\n\n\n\nIn 2021, after more than 35 years of research, the World Health Organization recommended widespread use of a vaccine candidate called RTS,S/AS01, or Mosquirix™, to prevent P. falciparum malaria in children.\nDevelopment of RTS,S/AS01 began in 1984, and soon after, a promising vaccine candidate entered preclinical research. Researchers performed tests on nonhuman subjects to collect data on how well the vaccine worked (efficacy), how much damage it could do to an organism (toxicity), and how the body affected the vaccine (pharmacokinetics).\nClinical research on humans began in 1992. Researchers conducted a Phase 1 safety and immunogenicity trial with 20 adults in The Gambia in 1997. Results suggested that the vaccine did not have any significant toxicity but did produce the expected antibodies.\nSeveral Phase 2 studies conducted over the next decade demonstrated the efficacy of the vaccine against several endpoints. A Phase 2b trial began in Mozambique in 2003 with more than 2,000 children. Each child was randomly assigned to receive 3 doses of RTS,S or a control vaccine. After 6 months, the prevalence of malaria was 37% lower in the treatment group than in the control group. This Phase 2 trial was an important proof-of-concept study.\nThe results of a large Phase 3 trial with more than 15,000 infants and young children in 7 African countries were published in 2015. Children who participated in the study were randomly assigned to 1 of 3 arms: (i) 3 doses of RTS,S and a booster dose at month 20, (ii) 3 doses of RTS,S and a booster dose of a comparator vaccine at month 20, or (iii) 4 doses of a comparator vaccine. RTS,S reduced clinical malaria cases by 28% and 18% among young children and infants, respectively, over a 3 to 4-year period. This Phase 3 trial demonstrated that the treatment was efficacious.\nOn the basis of these results, the European Medicines Agency issued a favorable “European scientific opinion”. This led the health ministries in Ghana, Kenya and Malawi to authorize a pilot study in 2019 to assess the feasibility of administering the required four doses of the vaccine as part of routine childhood immunization programs. After more than 800,000 children were immunized under this program, the WHO recommended that countries with moderate to high transmission adopt the vaccine.\n\n\n\n\n\nTranslational, Implementation, and Policy Research\n\n\n\nBauer and Kirchner make the point that our failure to put good ideas to use is not a new phenonmenon. The British Navy observed in 1601 that citrus cured scurvy on long sea voyages—and collected confirming ‘trial’ evidence in 1747—but it was not until 1795 that using citrus became routine practice.\n\nIt’s a long road from idea to impact (Morris et al., 2011), and most ideas don’t complete the trip (Bauer et al., 2020). Practitioners of translational research point to four key bottlenecks where ideas often stall (see also Figure 1.8):\n\nMorris, Z. S. et al. (2011). The answer is 17 years, what is the question: Understanding time lags in translational research. Journal of the Royal Society of Medicine, 104(12), 510–520.\n\nBauer, M. S. et al. (2020). Implementation science: What is it and why should I care? Psychiatry Research, 283, 112376.\n\nT1: Translation from basic science to clinical research\nT2: Translation from early clinical trials to Phase 3 trials and beyond with larger patient populations\nT3: Translation from efficacy trials (i.e., Phase 3 trials) to real-world effectiveness through implementation research\nT4: Translation from evidence about delivery at scale to the adoption of new policies\n\nTranslational research originally focused on moving from “bench to bedside”, or from basic research in the lab to clinical research with humans (T1), and later expanded to address the challenge of moving from early to late-stage human trials (T2). Today we recognize that other bottlenecks (T3 and T4) prevent good ideas from impacting population health and policy (Woolf, 2008).\n\nWoolf, S. H. (2008). The Meaning of Translational Research and Why It Matters. JAMA, 299(2), 211–213.\n\nDadonaite, B. (2019). Oral rehydration therapy: A low-tech solution that has saved millions of lives. In Our World in Data.\nFor instance, we know that giving children a simple mixture of water, sugar, and salts when they are dehydrated from diarrhea can prevent death in 90% of cases, but only 4 in 10 children receive this life saving oral rehydration therapy [ORT; Dadonaite (2019)]. And each year, several hundred thousand children under five years die from diarrheal diseases.\n\n\n\n\nFigure 1.7: Time from introduction to achievement of public health coverage targets. Source: AVAC Report 2017: Mixed Messages and How to Untangle Them. avac.org/report2017.\n\n\n\nThis is an example of a ‘delivery gap’ or ‘know-do’ gap in global health—the space between discovering what works and delivering the solution at scale (see Figure 1.7 for other examples).\n\n\nWork in this area has evolved independently across several disciplines. In addition to translational research and implementation research, you can find references to dissemination science, diffusion of innovations, quality improvement, knowledge transfer, and learning healthcare systems.\n\nKruk, M. E. et al. (2016). Transforming Global Health by Improving the Science of Scale-Up. PLOS Biology, 14(3), e1002360.\nPolicy and implementation research, or PIR, aims to close these gaps. PIR is the science of scale up (Kruk et al., 2016). It combines implementation research with health policy and systems research.\nImplementation research is the study of strategies for expanding the reach and coverage of tested ideas to improve population health. A common scenario is where intervention research demonstrates that a treatment is efficacious, such as ORT, but take-up is low and slow, thus limiting its impact. The implementation research question is how to best promote its use.\n\n\n\nHow is implementation science different from implementation research? Implementation science develops the frameworks and methods that are used in implementation research. Click here to watch an introductory workshop on implementation science from Northwestern University.\n\nHealth policy and systems research shares the same goal of population impact but takes an even broader view of the systemic and policy factors that can hinder or facilitate scale-up. Take for example a retrospective analysis by Lam et al. that evaluated the impact of policymaking in Uganda on ORT and zinc coverage (Lam et al., 2019). The authors triangulated data from various sources on government actions, distribution of supplies, and treatment with ORT, and estimated that the proportion of young children with diarrhea who received ORT increased 30-fold between 2011 and 2016, from 1% to 30%. Their policy analysis concluded that government actions likely made the difference.\n\nLam, F. et al. (2019). A retrospective mixed-methods evaluation of a national ORS and zinc scale-up program in Uganda between 2011 and 2016. Journal of Global Health, 9(1), 010504.\n\n\n\nMONITORING AND EVALUATION\nAnother area of applied work in global health is monitoring and evaluation (M&E), also known as program evaluation.\n\n\n\n\n\nEconomist and 2019 Nobel laureate Dr. Ester Duflo made a similar argument three decades after Campbell in a great TED Talk on social experiments to fight poverty.\n\n\nEvaluation\nProgram evaluation became commonplace in the United States by the end of the 1950s and grew dramatically in the 1960s as the federal government expanded and introduced new social programs. Lawmakers wanted accountability, and the evaluation of social programs took off (Rossi et al., 2003). But is program evaluation really research?\n\nCampbell, D. T. (1969). Reforms as experiments. American Psychologist, 24(4), 409.\nMethods giant Donald Campbell thought so (Campbell, 1969):\n\nThe United States…should be ready for an experimental approach to social reform, an approach in which we try out new programs designed to cure specific problems, in which we learn whether or not these programs are effective, and in which we retain, imitate, modify or discard them on the basis of their effectiveness on the multiple imperfect criteria available.\n\nBut not everyone agrees. Some have argued that program evaluation is really designed for program implementers and funders, and that the messy nature of program implementation requires a loosening of research standards (Cronbach, 1982).\n\nCronbach, L. J. (1982). Designing evaluations of educational and social programs. Jossey-Bass.\n\nRossi, P. H. et al. (2003). Evaluation: A systematic approach. Sage Publications.\nIn their introductory text on evaluation, Rossi et al. (2003) strike a balance in views on this question of whether program evaluation is research. Their answer is perhaps a bit unsatisfying but is arguably true nevertheless: It depends. In essence, program evaluations should be as rigorous as logistics, ethics, politics, and resources permit—and no less. Some evaluations are more rigorous than others and will meet the definition of research (a systematic investigation designed to develop or contribute to generalizable knowledge). For this reason, in Figure 1.8 I represent Monitoring & Evaluation as a block that intersects applied research but extends outside the research boundary.\n\nImpact Evaluations\n\n\n\n\n\nA clinical trialist who conducts RCTs for a living is unlikely to refer to a clinical trial as an ‘impact evaluation’, even though an RCT is a type of impact evaluation. This language is more commonly used by economists and others who study the impact of social sector programs and interventions. This video from the World Bank introduces impact evaluations.\n\nEvaluations can take different forms and serve various purposes. A subset of both applied research and program evaluation is the impact evaluation. An impact evaluation is a study that aims to quantify the causal effect—or impact—of a program or policy on some outcome of interest. There are several research designs that can generate evidence of impact. One example is the randomized controlled trial, or RCT, a mainstay of Phase 2 and Phase 3 clinical trials. Not all impact evaluations use random assignment to make causal inferences, but they all share the goal of making a cause-and-effect claim. As we’ll see in later chapters, the strength of this claim rests on the assumptions of the particular research design.\n\n\n\nMonitoring\nProgram monitoring is concerned with documenting the implementation of programs and interventions. How are resources being used? How many people participate? Does the program reach the intended targets? Not all programs are evaluated (“do they work?”), but most are monitored (“what happened?”) to some degree for accountability to funders. Researchers can use monitoring data to document participants’ exposure to the program and to conduct economic analyses related to program costs and impacts.\nA related activity is the process evaluation. A process evaluation goes beyond monitoring counts and tallies, largely an administrative task, to ask if a program is being delivered as intended. This gets at the question of fidelity of the implementation to the original design. Process evaluations are essential for impact evaluations: If a program fails to show an impact, the next question is why? Did the program fail because the idea or theory behind the program was wrong (theory failure)? Or was the implementation of the program so troubled that there was never a chance for success (implementation failure)?"
  },
  {
    "objectID": "ghr.html#who-funds-global-health-research",
    "href": "ghr.html#who-funds-global-health-research",
    "title": "1  Global Health Research",
    "section": "1.5 Who Funds Global Health Research?",
    "text": "1.5 Who Funds Global Health Research?\n\n\nAccording to Micah et al., “Development assistance for health refers to the financial and non-financial resources that are disbursed through international development agencies to maintain or improve health in low-income and middle-income countries.”\n\nMicah, A. E. et al. (2021). Tracking development assistance for health and for COVID-19: A review of development assistance, government, out-of-pocket, and other private spending on health for 204 countries and territories, 1990–2050. The Lancet, 398(10308), 1317–1343.\nBillions of dollars are spent on global health priorities every year. For instance, the international community disbursed $35-40 billion in development assistance for health yearly from 2010 to 2019. In 2020 this figure jumped to $55 billion because of the COVID-19 pandemic, with the United States accounting for one-quarter of the 2020 total ($14 billion) (Micah et al., 2021). Since the mid-2000s, most of this money has flowed to infectious disease programs (Figure @fig-funding).\n\n\n\n\nFigure 1.8: Development assistance for health by health focus area, 1990 to 2000.\n\n\n\nDevelopment assistance for health includes funded research, but it’s not inclusive of all research in low- and middle-income countries (e.g., does not include domestic spending on research). Nor does it capture research on global health issues in wealthy nations. Inequities in health exist everywhere, so by definition global health research is a broad domain. It’s difficult to put a dollar amount on the enterprise as a whole. A 2013 analysis estimated that the global investment in health research and development (R&D) topped $300 billion (in 2021 dollars) (Røttingen et al., 2013).\n\nRøttingen, J.-A. et al. (2013). Mapping of available health research and development data: What’s there, what’s missing, and what role is there for a global observatory? Lancet (London, England), 382(9900), 1286–1307.\n\nPolicy Cures Research. (n.d.). G-FINDER data portal.\nAccording to this analysis, most investments in health R&D come from private industry (60%), with the rest coming from the public sector (30%) and other sources (10%). Very little money is directed to pharmaceutical products and technologies for global health priorities that disproportionately affect poor countries—less than $4 billion in 2019 (Policy Cures Research, n.d.). In this 2019 accounting, public and philanthropic funders provided almost 90% of the money. The two leading funders were the United States National Institutes of Health (44%) and the Bill and Melinda Gates Foundation (16%), contributing nearly two-thirds of all research dollars between them.\nThe model for investments in R&D for health is funding from the rich, to the rich, (mostly) for the rich."
  },
  {
    "objectID": "ghr.html#who-sets-the-agenda-and-conducts-global-health-research",
    "href": "ghr.html#who-sets-the-agenda-and-conducts-global-health-research",
    "title": "1  Global Health Research",
    "section": "1.6 Who Sets the Agenda and Conducts Global Health Research?",
    "text": "1.6 Who Sets the Agenda and Conducts Global Health Research?\nThis is important context because funders have an outsized role in setting the research agenda (Sridhar, 2012). Outside of industry, researchers depend primarily on grants to fund their work. As nearly all global health research funding comes from governments and philanthropies in high-income countries, the global health research agenda is set in large part by the wealthy (Ii et al., 2018).\n\nSridhar, D. (2012). Who Sets the Global Health Research Agenda? The Challenge of Multi-Bi Financing. PLOS Medicine, 9(9), e1001312.\n\nIi, Y. B. et al. (2018). Advancing equitable global health research partnerships in Africa. BMJ Global Health, 3(4), e000868.\n\nWHO. (n.d.). Investments on grants for biomedical research by funder, type of grant, health category and recipient.\n\nKyobutungi, C. et al. (2021). PLOS Global Public Health, charting a new path towards equity, diversity and inclusion in global health. PLOS Global Public Health, 1(10), e0000038.\nThe global health research agenda is also, in large part, carried out by the wealthy. Only a fraction of 1% of funding for biomedical research goes directly to recipients in low-income countries (WHO, n.d.). In-country researchers too often only play the role of partner or collaborator, rather than principal investigator, if even consulted (Kyobutungi et al., 2021). We’ll revisit these power imbalances, and what can be done to chart a more equitable and inclusive course for global health research, in the next chapter."
  },
  {
    "objectID": "ghr.html#where-is-global-health-research-published",
    "href": "ghr.html#where-is-global-health-research-published",
    "title": "1  Global Health Research",
    "section": "1.7 Where is Global Health Research Published?",
    "text": "1.7 Where is Global Health Research Published?\n\n\n\n\n\nEditors at The Lancet discuss publishing global health research.\n\nGlobal health research is published in medical journals (e.g., The Lancet, JAMA), general science journals (e.g., Science, Nature, PLOS ONE), discipline-specific journals (e.g., The Journal of Immunology, Epidemiology), and disease-specific journals (e.g., AIDS, Malaria Journal). Journals specializing in global health research include The Lancet Global Health, BMJ Global Health, Global Health: Science and Practice, and PLOS Global Public Health."
  },
  {
    "objectID": "collaborations.html",
    "href": "collaborations.html",
    "title": "2  Build Collaborations",
    "section": "",
    "text": "Global health research is a team effort. Solo-authored research papers are rare in our field, even for secondary analyses of existing data. The issues that we choose to study—and hopefully influence—are complex, making collaboration essential. Teams often span time zones, disciplinary backgrounds, levels of training and seniority, nationalities, cultures, and perspectives. This makes collaboration rewarding, and our science is better for it, but being a good collaborator takes effort and practice."
  },
  {
    "objectID": "collaborations.html#decolonizing-global-health",
    "href": "collaborations.html#decolonizing-global-health",
    "title": "2  Build Collaborations",
    "section": "2.1 Decolonizing Global Health",
    "text": "2.1 Decolonizing Global Health\nToday’s global health emphasizes equity in healthcare access and health outcomes, but we can trace some of its lineage back through international health and tropical medicine to European colonization and ‘colonial medicine’—back to a time when the motivation was protecting colonial rulers and promoting national interests, not equity (Holst, 2020). Global health has come a long way since then—as has the health and wellbeing of people everywhere—but some argue that our approach to collaboration in global health has not fully parted ways with its colonial influences (Abimbola et al., 2020).\n\nHolst, J. (2020). Global health–emergence, hegemonic trends and biomedical reductionism. Globalization and Health, 16(1), 1–11.\n\nAbimbola, S. et al. (2020). Will global health survive its decolonisation? Lancet (London, England), 396(10263), 1627–1628.\n\nWHO. (n.d.). Investments on grants for biomedical research by funder, type of grant, health category and recipient.\n\nKyobutungi, C. et al. (2021). PLOS Global Public Health, charting a new path towards equity, diversity and inclusion in global health. PLOS Global Public Health, 1(10), e0000038.\nThis is because many collaborations in global health have been, and continue to be, an unequal venture, not a true partnership. In the previous chapter, I noted that the global health research agenda is, in large part, set and carried out by the wealthy. Less than 1% of funding for biomedical research goes directly to scientists in low-income countries (WHO, n.d.), and consequently, authors from the Global North are overrepresented in scientific publications (Kyobutungi et al., 2021).\nCalls to ‘decolonize’ global health are not new (Costello et al., 2000), but we’ve witnessed a new urgency in recent years, with students and trainees often leading the way. There is a compelling argument that says the only path to decolonization is radical transformation of institutions (Hirsch, 2021); efforts to improve diversity and inclusion are welcome, but they are not a substitute for dismantling a system that was designed to benefit those with power (Pai, n.d.). Abimbola and Pai frame the aims of the decolonize global health movement as follows:\n\nCostello, A. et al. (2000). Moving to research partnerships in developing countries. Bmj, 321(7264), 827–829.\n\nHirsch, L. A. (2021). Is it possible to decolonise global health institutions? Lancet, 397(10270), 189–190.\n\nPai, M. (n.d.). Decolonizing Global Health: A Moment To Reflect On A Movement. In Forbes.\n\nTo decolonise global health is to remove all forms of supremacy within all spaces of global health practice, within countries, between countries, and at the global level. Supremacy is not restricted to White supremacy or male domination. It concerns what happens not only between people from HICs and LMICs but also what happens between groups and individuals within HICs and within LMICs. Supremacy is there, glaringly, in how global health organisations operate, who runs them, where they are located, who holds the purse strings, who sets the agenda, and whose views, histories, and knowledge are taken seriously.\n\nThe ground is shifting beneath global health. Time will tell whether this moment will lead to institutional reforms, but as individuals we don’t need to wait to reform how we approach collaborations. I suspect student readers wouldn’t have it any other way."
  },
  {
    "objectID": "collaborations.html#team-science",
    "href": "collaborations.html#team-science",
    "title": "2  Build Collaborations",
    "section": "2.2 Team Science",
    "text": "2.2 Team Science\nMost modern science, and global health research in particular, is a never-ending series of group projects. This might be a chilling prospect if you haven’t had good experiences with group work, but I’m here to tell you that team science can be very rewarding and productive given the right environment. As it’s very likely that you’ll join many teams in your global health career, we should discuss what makes a team effective and how to prepare yourself to be a good teammate.\nThe National Cancer Institute of the NIH (U.S.) defines team science as:\n\na collaborative effort to address a scientific challenge that leverages the strengths and expertise of professionals, oftentimes trained in different fields\n\nTeams span the continuum from small investigator-led ‘labs’ to large, highly integrated groups of professionals sharing leadership responsibilities (Bennett et al., 2018). Increasingly, given the complexity of today’s research problems and a trend toward specialization in research expertise and methods, teams bring together people from different disciplines and locations. While the payoff of creating more diverse and skilled teams can be substantial, so are the challenges.\n\nBennett, L. M. et al. (2018). Collaboration team science: Field guide. US Department of Health & Human Services, National Institutes of Health.\nRecognizing the growing importance of team science, researchers established a new field of inquiry in 2006 called the Science-of-Team-Science to study what makes scientific teams click. Many of the findings have made their way into Collaboration and Team Science: A Field Guide, a handbook published by the NIH in 2010 and updated in 2018. In the following sections, I’ll walk you through each of the Field Guide’s top ten takeaways for getting the most out of team science.\n\nVISION\n\nA strong and captivating vision attracts people to the team and provides a foundation for achieving team goals. Shared vision provides a focal point around which a highly functioning team can coalesce.\n\nSome science collaborations are like the 2001 American heist comedy film, Ocean’s Eleven. In the movie, Danny Ocean, played by George Clooney, is released from prison and immediately begins recruiting a hand-selected, nine-member crew to rob three of the biggest casinos in Las Vegas. One-by-one, Ocean pitches them on the idea and secures their cooperation. Ocean’s vision was simple: steal $150 million in cash without getting caught. Once the team was in place, they worked together to hatch a plan.\nOthers collaborations are more like the 1995 film, Apollo 13, about America’s third crewed mission to the moon. Fifty-five minutes into the mission, when the spacecraft was about 330,000 km from Earth, there was an explosion in the service module that caused oxygen to leak into space. The lunar landing was aborted, and the three-man crew moved into the lunar module for a dramatic rescue attempt. The team on the ground at mission control and the astronauts in space had to work together to find a way return the spacecraft to Earth before the astronauts ran out of water and oxygen.\nIn both movies, the teams had a clearly defined and shared vision. As well, team members understood their roles and how they were to contribute to the vision. Research on teams suggests that these factors are key to creating group cohesion. When team members can’t articulate the vision or don’t understand how their contributions fit into the bigger picture, the team’s work often suffers.\nThe stories portrayed in these films differed in an important way with respect to teams, however: in how the vision was created. In Ocean’s Eleven, the vision belonged to Danny Ocean and he made a compelling case to prospective team members. But in Apollo 13, the team co-created the vision in the context of an ongoing collaboration.\n\n\nWe’ll talk more about how to write a compelling Specific Aims document later in the book. It’s a great format for articulating a vision.\nIn this respect, the Ocean’s Eleven model is more prevalent in global health research. A lead scientist—the principal investigator—finds a funding opportunity, writes a short concept note, often called a Specific Aims document, and invites collaborators to join the proposal. There is nothing inherently wrong with this model, but the opening of this chapter should lead us to reflect on this privilege. Namely, whose vision becomes reality in global health is driven by whose vision is funded. Funding decisions tend to favor scholars from the Global North, so visions of the Global South are underrepresented in global health research. One way we can promote change is to build lasting collaborations. When collaborators continue to work together over time, visions can come from anyone on the mission.\n\n\nTEAM EVOLUTION AND DYNAMICS\n\nResearch teams form and develop through critical stages to achieve their highest potential (Forming, Storming, Norming, Performing). A positive team dynamic sustains and further strengthens a research team, enabling it to achieve successful outcomes.\n\nThe most famous framework for understanding how teams evolve is Tuckman’s 1965 Model of Group Development, as described in Field Guide:\n\nForming—The team is established using either a top-down (Ocean’s Eleven) or bottom-up (Apollo 13) approach.\nStorming—Team members establish roles and responsibilities. This process may trigger disagreements or “turf battles” and reveal a reluctance to appreciate the perspectives and contributions of people from different disciplines or training. However, if collegial disagreement is supported and premature pressure to consensus is resisted, people will begin to open up to one another.\nNorming—Team members begin to work together effectively and efficiently, start to develop trust and comfort with one another, and learn they can rely on each other.\nPerforming—The team works together seamlessly, focuses on a shared goal, and efficiently resolves issues or problems that emerge.\nAdjourning or Transforming—Once the team accomplishes its goal, it can celebrate the accomplishment and disband or take on a new problem.\n\nA proven way to strengthen team dynamics is to maintain a collegial environment where members are recognized for their contributions and given opportunities to grow.\n\n\nTRUST\n\nIt is almost impossible to imagine a successful collaboration without trust. Trust provides the foundation for a team. Without trust it is nearly impossible to sustain a collaboration.\n\nNew teams can establish trust by establishing rules and norms. It’s common for teams to co-create a written charter or collaboration agreement that details how their members will work together, resolve disputes, share the workload, and share the credit. This practice is particularly important when teams bring together people from different backgrounds, disciplinary and otherwise, where the existing norms can differ.\n\n\nThis is calculus-based trust. You trust that other people will follow the rules because not doing so has consequences. Another form of trust is competency-based trust: when your reputation or expertise precedes you and folks know that you can be trusted to perform.\nWith time and experience, teams can build deeper forms of identity-based trust based on personal connections and a recognition of shared values. This type of trust is often earned through actions and should not be assumed. Creating and maintaining trust takes substantial effort.\n\n\nCOMMUNICATION\n\nEffective communication within and outside a research team contributes to effective group functioning. It depends on a safe environment where team members can openly share and discuss new scientific ideas and take research into new, previously unconsidered directions as well as ensure that difficult conversations can take place.\n\nTrust and communication are reciprocal. Teams that trust each other communicate openly, and open communication builds trust. However, effective communication can be challenging for new inter-disciplinary teams where members may not share a vocabulary for the science. A recurring theme in this chapter is that successful teams make space for and devote time to establishing common frameworks, including a shared vocabulary.\nThis extends to creating expectations around communication and participation. How often will you meet as a team? What will the format be, and how will you give opportunities for members to be heard? What type of communication is suitable for email vs business messaging apps? When should an email or message thread become a quick phone call or meet-up?\n\n\nCONFLICT AND DISAGREEMENT\n\nConflict can be both a resource and a challenge—a resource because disagreement can expand thinking, add new knowledge to a complex scientific problem, and stimulate new directions for research. A challenge because if it is not handled skillfully, conflict impedes effective team functioning and stifles scientific advancement.\n\nWhenever teams are communicating, conflict and disagreement are possible. In fact, effective teams often encourage the type of critical reflection and constructive criticism that can make conflict and disagreement more likely. This is because they know that conflict is a normal part of collaboration and that, when properly managed, conflict can lead to progress and cohesion. Of course, it’s also true that scientific conflict and disagreement can lead to interpersonal conflict and tension that impairs the team’s ability to achieve its vision.\nTeam leaders play a large role in keeping debate and disagreement productive and in mediating conflicts, but each of us is responsible for our own contributions to the collective dynamic. The Field Guide recommends that we consider the following steps for managing and resolving conflict:\n\nUnderstand the culture and the context of conflict—seek out the meaning of the conflict for yourself and/or the other parties.\nActively listen—assure others you have heard what they said and ask questions to confirm your understanding.\nAcknowledge emotions—they will likely be part of the conflict, but expressing them and hearing them can help lift barriers to resolution.\nLook beneath the surface for hidden meaning—hidden fears, needs, histories, or goals may be the underlying source of the problem.\nSeparate what matters from what is in the way—get away from discussing who is right or wrong and focus more on how to satisfy mutual needs.\nLearn from difficult behaviors—let those experiences help you develop your skills in managing difficult situations and having empathy for and patience with others.\nSolve problems creatively and negotiate collaboratively—this also means committing to action.\nUnderstand why others might be resistant to change—the problem could be an unmet need.\n\n\n\nSELF-AWARENESS AND EMOTIONAL INTELLIGENCE\n\nEmotional Intelligence among team members contributes to the effective functioning of research teams. Self awareness gives people greater control over their own emotional reactions to others, improves the quality of their interactions, and helps build other-awareness.\n\nResearch and science textbooks do not typically emphasize the importance of self-reflection, but the ability to reflect and become self-aware is a core skill required of today’s team science. Someone who lacks self-awareness has limited options for responding to challenging colleagues. People who can take someone else’s perspective and embrace what makes them different have a superpower in team science.\nReflection is also key in collaborations that bring together people from different backgrounds. Whether your work takes you to a new neighborhood or halfway around the world, it’s critical to have the humility to listen and learn.\n\n\nLEADERSHIP\n\nStrong collaborative leadership elicits and capitalizes on the team members’ strengths and is a critical component of team success. Leadership can be demonstrated by every team member, not just the formal leader(s).\n\nI’ve worked with many effective leaders throughout my career. Although they took different approaches to leadership, each person possessed an ability to encourage and motivate individual team members, articulate and maintain a shared vision, and have difficult conversations. The ineffective leaders I’ve encountered were variously disengaged, timid, defensive, or hostile.\nEvery scientific collaboration you join as a trainee is an opportunity to observe and practice leadership. Take notes on what you appreciate in your leaders, and reflect on how poor leadership stifles progress. Spend time developing self-awareness and other-awareness, and approach difficult conversations with openness.\n\n\nMENTORING\n\nMentoring is an indispensable aspect of successful collaboration. A mentor recognizes the strengths of each team member, identifies areas in which newer scientists have the greatest potential to grow, and can help coach people to attain their aspirations. With good mentoring, the development of scientists is synchronous with strengthening team dynamics.\n\nOne of the best investments you can make as a trainee is in finding a good mentor. The return should go far beyond leaving with a good letter of recommendation. A good mentor-mentee relationship can set a strong foundation for a scientific career. If you look at the curriculum vitae—or scholarly record—of successful scientists, you’ll likely see the fingerprints of one or more helpful mentors. Mentors can expose you to new collaborations and resources, help to nurture your ideas, steer you around traps, and teach you the ‘hidden curriculum’ of your scientific discipline that you won’t learn in the classroom.\nFinding a mentor can be a daunting task, especially if you are introverted. Even when you get up the courage to reach out to a potential mentor, your email might go unreturned or come back without an offer to meet. Keep trying, but consider this advice:\n\nAttend scientific talks and department events when possible and introduce yourself\nReach out to the mentor’s other students to learn more about potential opportunities\nKeep your correspondence short with a clear request\nDo you homework—general requests to learn about a person’s work are less effective than a specific statement of how your interests align\n\n\n\nRECOGNITION AND SHARING SUCCESS\n\nIndividual contributions should be recognized, reviewed, and rewarded in the context of a collaboration. Recognition and reward of all team members should be done thoughtfully and fairly in the context of the team and the institution.\n\nMost years on December 10, going back to 1901, the King of Sweden awards several prizes in fields such as medicine, chemistry, and physics, in honor of Swedish inventor Alfred Nobel. Each prize can be given to a single laureate or shared by no more than three laureates.\nIn 2015, the Nobel Prize in Physiology or Medicine was divided between three scientists in recognition of two discoveries that shaped treatments in global health. William Campbell and Satoshi Ōmura shared half of the prize “for their discoveries concerning a novel therapy against infections caused by roundworm parasites”, and Tu Youyou received the other half “for her discoveries concerning a novel therapy against Malaria”.\nThe importance of these discoveries cannot be overstated. Ivermectin (Ōmura and Campbell) and artemisinin (Tu) have helped hundreds of millions of people. These accomplishments deserved to be recognized, and these scientists played significant roles. Tu Youyou even volunteered to be the first human to test her team’s new drug!\nThat said, these individual awards don’t recognize the teams behind this work. Campbell noted as much in his Nobel Lecture, taking a moment to graciously acknowledge his collaborators (Campbell, n.d.):\n\nCampbell, W. C. (n.d.). Nobel lecture.\n\nThere is a question that warrants a slight digression here. In the past few weeks I have often been asked how I felt when I heard that I had won the Nobel Prize. I can say without hesitation that my mind was instantly flooded with two emotions. One was a sense of joy and gratitude. The other was a feeling of sadness—sadness that so many of the people who made this discovery a success could not be named individually. But I represent the research team at Merck & Co., Inc., and in that role I feel honored and grateful beyond imagining.\n\nDespite the growing prevalence of team science, professional recognition and career advancement still depend in large part on individual achievement. This is one reason that it is critical for teams to plan ahead to share recognition and credit.\n\n\nDepending on your line of research, credit might also come in the form of patents.\n\nICMJE. (n.d.). Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly work in Medical Journals.\nOne of the clearest records of achievement in science is academic publication. Decisions about who receives recognition as an author of a scientific paper can help to make or break careers. On some research teams, the leader decides who deserves to be an author with little to no input from more junior members. This has the potential to lead to resentment and create competition rather than collaboration. Team science advocates encourage a different approach: creating a transparent plan as soon as possible to identify how members will contribute, be recognized, and share the credit. Sometimes this credit will come in the form of authorship. The International Committee of Medical Journal Editors, or ICMJE, recommends four criteria that should determine who should be offered the opportunity (ICMJE, n.d.):\n\n\nA person who meets some but not all of the criteria should be acknowledged in the paper for their contributions.\n\nMakes substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND\nDrafts the work or revises it critically for important intellectual content; AND\nGives final approval of the version to be published; AND\nAgrees to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.\n\n\n\nIn recent years it has become more common for authors to include a footnote on the title page of an article indicating that two or more authors should be considered to be co-first authors in recognition of equal contributions.\nIt’s often not enough to decide who gets to be an author. Many teams also have to think through order of authorship. In some fields, including public health and medicine, author order is interpreted to be a reflection of the magnitude of each person’s contributions. For instance, the first author is the lead author and receives the most credit in the eyes of some hiring and promotion committees—“look, they are establishing their ‘independence’”. The principal investigator might take this position or choose instead to go last in the order, taking what is known as the senior author slot. Everyone in between is a middle author. On some teams, the closer to the front you fall, the more work might be expected of you.\n\n\nLarge teams spanning multiple organizations sometimes form study groups and publish under the name of the group. For instance, I’ve published several papers with the Depression Screening Data PHQ Collaboration, or DEPRESSD.\nThink this is too complicated? Then become an economist! Economists often default to alphabetical order. (But if your name is Zarby you might as well stick to medicine.)\n\n\nNAVIGATING AND LEVERAGING NETWORKS AND SYSTEMS\n\nHighly collaborative teams can transcend different organizational structures, extending their reach across and beyond the organization. They often function within the context of multiple and sometimes interconnected systems, and they can help establish strong networks of researchers who together can accomplish more than they could as individuals.\n\nEvery new job requires you to learn the lay of the land, and jobs in global health and academia are no exception. But as team science and interdisciplinary research become more common, this task gets increasingly difficult. It’s part of your team leader’s responsibility to help you understand and navigate the system in which your team operates, but I want to leave you with a few common networks that you’ll find in global health:\nAcademic Institutions: University > School > Department > Center\nInstitutes: Often sit outside of schools and drawing faculty from across the University. Can have one or more centers.\nWorking/Study Groups: A formal or informal group of investigators from one or more institutions that share a common interest or purpose.\nConsortiums: A collection of organizations that are partnering on a specific project or initiative. Consortiums are often led by one organization (the prime) that makes subawards or subcontracts to several partner organizations (subs).\nCommissions/Expert Panels: A temporary group established by a body such as a journal that brings together experts to study an issue and create a report or recommendations.\n\n\n\n\n\n\n\nBONUS PRINCIPLE: Fairness\n\n\n\nA challenge for many collaborators is a lack of time and attention. This is particularly true for senior collaborators who might be juggling several projects, as well as for collaborators of all ranks who are not adequately funded by the project. This routinely happens in global health projects where researchers and practitioners from under-resourced settings are asked to join a team but are not compensated and do not have protected research time from their institutions. It’s common in these situations to spend a portion of every meeting reminding team members of the project goals—the vision.\nWhen your team has busy, but well-funded senior colleagues, creating a vision statement and always orienting the team to this North Star can be a helpful strategy. But even the best crafted documents are no substitute for offering funded time when you are asking resource-constrained colleagues to lend their time and attention to your vision."
  },
  {
    "objectID": "collaborations.html#community-based-participatory-research",
    "href": "collaborations.html#community-based-participatory-research",
    "title": "2  Build Collaborations",
    "section": "2.3 Community-Based Participatory Research",
    "text": "2.3 Community-Based Participatory Research\nThe ultimate form of team science might be community-based participatory research, or CBPR (Israel et al., 1998). In CBPR, research teams join with community members to define the vision, generate knowledge, and create positive change. CBPR requires researchers to share power and credit with people who are most often ‘subjects’, not partners.\n\nIsrael, B. A. et al. (1998). Review of community-based research: Assessing partnership approaches to improve public health. Annual Review of Public Health, 19(1), 173–202.\n\nPuffer, E. S. et al. (2013). Developing a family-based HIV prevention intervention in rural kenya: Challenges in conducting community-based participatory research. Journal of Empirical Research on Human Research Ethics, 8(2), 119–128.\nLet’s look at an example from the HIV prevention literature (Puffer et al., 2013). A US-based team with links to a local non-profit organization in rural Kenya recruited 20 community members—church leaders, healthcare staff, teachers, village chiefs—to join a community advisory committee. This academic-community partnership collaborated on all aspects of the research, starting with workshops designed to share expertise and establish a common vision. The team then planned an assessment of community needs and resources and jointly analyzed and interpreted the data. This was followed by a series of intervention development workshops to create a model of HIV prevention that was informed by science and local priorities. The partnership continued through the design and implementation of a randomized controlled pilot trial to test the intervention."
  },
  {
    "objectID": "causalinference.html",
    "href": "causalinference.html",
    "title": "3  Causal Inference",
    "section": "",
    "text": "Extra! Extra! Read all about it: “New study suggests coffee could literally be a lifesaver” (CNN Wire, 2015).\nThis is a real headline about a study published in the journal Circulation. Now, I’m as big a coffee fan as the next guy, but literally a life saver? Here’s what the study authors wrote in their paper (Ding et al., 2015):\n“Associated with” tells us that there’s a relationship between mortality and coffee consumption in the observed data. The sort of people who drink a cup of coffee daily have a 5% lower risk of dying over 2 to 3 decades. (This is a 0.7% absolute decrease in the incidence of mortality according to my back of the envelope analysis.) Does this mean that coffee prevents death?\nThe study authors say no. But also, maybe! This is what I call Causal Deniability. (For more examples, see Haber et al., 2018.)\nStep 1: Avoid the word “causal” and warn that correlation is not causation.\nStep 2: Ignore the warning and make policy or health recommendations based on a causal interpretation of the findings.\nSo which is it, a non-causal association or a causal effect? Hernán (2018) argues that scientists need to stop the charade:\nAccording to Hernán (2018), the point is that we have to be clear about our scientific goals and use language that reflects these goals. To riff on his idea a bit: Do we want to determine whether “the sort of people who drink a cup of coffee daily have a lower risk of dying” or do we want to determine whether “drinking a cup of coffee daily lowers the risk of dying”?\nIt’s almost always the latter.1 And to answer this question, we need causal inference."
  },
  {
    "objectID": "causalinference.html#what-is-causal-inference",
    "href": "causalinference.html#what-is-causal-inference",
    "title": "3  Causal Inference",
    "section": "3.1 What is Causal Inference?",
    "text": "3.1 What is Causal Inference?\n\n\n\nCasual Inference Podcast, Season 3, Episode 6, A Casual Look at Causal Inference History.\n\nCausal inference is what we do when we identify and estimate the causal effect of some proposed cause on an outcome of interest. We use causal inference methods in global health to answer key questions about health policy and practice. Do bed nets prevent malaria, and by how much? Is it better to subsidize bed nets or sell them at full retail cost? And so on.\n\n\n\n\nFigure 3.1: Causes, effects, and outcomes\n\n\n\nAs someone who has likely perfected the art of causal inference in your daily life, you might be surprised to learn that causal inference in science is still a rapidly evolving field. Even core terms like cause and effect are up for debate.\n\n\n\n\n\n\n\nEffects of causes or causes of effects?\n\n\n\nThe most common type of causal inference question we ask is about the effects of causes. What is the effect of 𝑋 on 𝑌? For instance, what is the effect of a new therapy on depression severity? Given a well-defined cause, 𝑋, we can estimate what happens to 𝑌 if 𝑋 changes. Questions about the causes of effects—what causes 𝑌?—are harder to answer. For example, what causes depression?\n\n\n\n\nCAUSES\n\n\n\n\n\nWatch Dr. Judea Pearl discuss what he calls the new science of cause and effect.\n\nThe Turing Award-winning computer scientist Dr. Judea Pearl and his co-author, mathematician-turned-science writer Dr. Dana Mackenzie, offered the following definition of causes in their 2018 instant classic, The Book of Why (Pearl et al., 2018):\n\nA variable 𝑋 is a cause of 𝑌 if 𝑌 “listens” to 𝑋 and determines its value in response to what it hears\n\nThis definition has several implications for causal relationships (Shadish et al., 2002):\n\nCauses must come before effects. 𝑋 speaks and then 𝑌 listens.\n\nCauses and effects are associated, meaning they go together or covary. When 𝑋 happens, 𝑌 is more likely to happen. I say “more likely” because the effect does not always need to happen for there to be a causal relationship between 𝑋 and 𝑌. For instance, smoking increases the probability of developing lung cancer, but not all smokers will develop lung cancer. Most of the relationships we study in global health are like this—probabilistic in nature, not deterministic.\nThere are no other plausible alternative explanations for the effect other than the proposed cause. In other words, 𝑌 listens to 𝑋 and not to something else that also happens to be related to 𝑋. During the smoking debate of the 1950s and 1960s, some proponents of smoking asked whether the apparent causal link between smoking and lung cancer could be explained by a smoking gene that predisposed people to smoking and to lung cancer.2\n\nThe need to rule out plausible alternative explanations keeps many researchers up at night. Claims from studies that fail to do this convincingly are characterized as having low internal validity. In other words, there is not a strong justification for inferring that the observed relationship between 𝑋 and 𝑌 is causal.\n\nCauses in global health research\nWe study a variety of potential causes in global health research and call them by different names. For instance, global mental health researchers often develop and test interventions delivered to individuals or groups to prevent or treat conditions such as depression. Development agencies administer programs to improve people’s well-being, including economic assistance programs intended to reduce poverty. Clinical researchers and biostatisticians test the efficacy of drugs and medical devices, generally referred to as treatments or therapies, on health outcomes, such as the COVID-19 vaccinations developed in 2020. Policy researchers and health economists study the health and financial impacts of policies, such as removing fees to deliver a baby at public health facilities. Epidemiologists estimate the effect of exposures, such as smoking, on the health status or prognosis of a target population.\n\n\n\n\n\n\n\nNo causation without manipulation?\n\n\n\nSome scholars believe that it must be possible to manipulate, or change, a variable for that variable to be considered a cause. This would exclude immutable variables such as age and genetic sex as causes of effects because there is not currently a way to plausibly intervene to change them. This is sometimes framed as the need for a “well-defined intervention”. I don’t personally agree with the “no causation without manipulation” mantra, but I value the way it encourages us to focus on research questions that can improve public health.\n\n\n\n\n\n\nEFFECTS\nCausal inference is an exercise in counterfactual thinking, full of “what if” questions about the road not taken. We ask ourselves these questions all the time. What would have happened if I had taken that job? Said “yes” instead of “no”? How would life be different today?\n\nCounterfactuals and potential outcomes\nA counterfactual is the hypothetical state of a “what if” question. With counterfactual thinking, there is what actually happened, and then there is the hypothetical counterfactual of what would have happened, counter to fact, under the alternative scenario. The difference between what did happen and what would have happened is a known as the causal effect.\nRobert Frost fans see the problem.\n\n\n\n\n\n“The Road Not Taken”, by Robert Frost, The Atlantic Monthly, 1915.\n\n\n\nTwo roads diverged in a yellow wood, and sorry I could not travel both and be one traveler…\n\nRobert has to choose one road; he can’t take both simultaneously. Robert can either take the road more traveled, a decision we’ll call 𝑋 = 0, or he can take the road less traveled, a decision we’ll call 𝑋 = 1.\n\n\n\n\n\n\n\nWhat’s with the Xs and Ys, 1s and 0s?\n\n\n\nIn some ways it might be easier to refer to Robert’s decision as the variable road, or 𝑅, and set the values of road to “more traveled” or “less traveled”, representing his two choices. But instead I’m referring to his decision as 𝑋 and to the values of 𝑋 as 0 (more traveled) or 1 (less traveled). Why?\nOften we refer to potential causes as 𝑋 and to response variables as 𝑌. And typically, when the treatment (or exposure) 𝑋 can take two levels, such as treated/not treated, we label treated 1, and not treated 0.\nIn this example, I imagine Robert looking left and then looking right. Observing that the second path was “grassy and wanted wear”, he decided to go right, taking the “one less traveled by”. Frost claims that his decision to take the uncommon path “made all the difference”, so I’m labeling this path (less traveled) as the treatment, 𝑋 = 1.\n\n\n\nRobert’s two choices correspond to two potential outcomes, or states of the world, that he could experience (Rubin, 1974). There is the potential outcome that results from taking the road more traveled, and the potential outcome that results from taking the road less traveled. We’ll call these scenarios Y𝑖X=0 (what happens if he takes the road more traveled) and Y𝑖X=1 (what happens if he takes the road less traveled).\n\nRubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology, 66(5), 688.\nSo what does he do? He famously takes the road less traveled. Robert’s factual outcome is what happens after making this choice. His other potential outcome will never be observed. Taking the road more traveled is now the counterfactual. He can only wonder what would have happened, counter to fact, if he had taken the beaten path.\n\n\nCould Robert experience the counterfactual by returning at a later date to take the other road? No, because he wouldn’t be the same person who stood there at the start. He could not un-experience the road less traveled. Also, we’d be measuring his happiness at two different points in time. Besides, he did not expect to return: “Yet knowing how way leads on to way / I doubted if I should ever come back.”\nAnd yet, Robert boldly claims that taking the road less traveled “made all the difference”. How can he know for sure? We defined causal effects as the difference between what did happen and what would have happened, but we only observed what happened, not what would have. Therefore, we have a missing data problem.\nThis is what’s often called the fundamental problem of causal inference (Holland, 1986): we only get to observe one potential outcome for any given person (or unit, more generally). The causal effect of taking the road less traveled is the difference in potential outcomes: 𝛿i = 𝑌𝑖𝑋=1 - 𝑌𝑖𝑋=0, but 𝑌𝑖𝑋=0 is missing. Therefore, we can’t measure this effect for Robert (𝑖).\n\nHolland, P. W. (1986). Statistics and causal inference. Journal of the American Statistical Association, 81(396), 945–960.\n\n\nAverage treatment effect\nWe can, however, compare groups of people like Robert who take one road or the other and estimate the average treatment effect, or ATE. I’m emphasizing “estimate” because truly calculating the ATE would require knowing both potential outcomes for each person (or unit, like classrooms or schools). We can only observe one potential outcome for any given person, but let’s ignore this for a moment to understand the true ATE.\n\n\nThe average treatment effect is also called the sample average treatment effect, or SATE.\nWhile we’re pretending, let’s imagine that the response variable Robert writes about in his poem is happiness later in life, and happiness, or 𝑌, is measured on a scale of 0 to 10 where 0 is not at all happy and 10 is very happy.\nFigure 3.2 shows fictional happiness data for a sample of 12 people, including Robert, under both potential outcomes. Notice how each person in the left panel has two values: the happiness that would result if they took the road less traveled (𝑋=1) and the happiness that would result if they took the road more traveled (𝑋=0). Some people, like Traveler 1, would be happiest taking the road more traveled, whereas other people, such as Robert (11), would find greater happiness on the road less traveled. (Remember, we’re pretending here. We never observe both potential outcomes.)\n\n\n\n\nFigure 3.2: Potential outcomes, part 1.\n\n\n\nAs shown in the right panel of Figure 3.2, the ATE is calculated as the difference between group averages (𝐸[𝑌𝑖𝑋=1]-𝐸[𝑌𝑖𝑋=0]), which is equivalent to the average of traveler’s individual causal effects. In this example where we are all knowing, the ATE is 1.5; taking the road more traveled increases happiness on average by 1.5 points on a scale of 0 to 10.\nWe’re not all knowing, of course, and we only get to observe one potential outcome for each person. This means we have to estimate the ATE by comparing people like Robert who take the road less traveled to people who take the road more traveled. But how do people come to take one road versus the other?\nFigure 3.3 shows two scenarios (of an infinite number). On the left (A), travelers are randomly assigned to a road. Imagine that they come to the fork in the road and pull directions out of a hat. Half are assigned to the road less traveled, and half to the road more traveled. On the right (B), however, travelers choose a road themselves. Imagine that they go with their gut and all happen to pick the road that maximizes their individual happiness. In both panels, the grey dots represent the unobserved counterfactuals.\n\n\n\n\nFigure 3.3: Potential outcomes, part 2.\n\n\n\nNotice that under perfect randomization (left, A), the estimated ATE 1.5 is equal to the true (but unknowable) ATE. But on the right (B), when travelers selected their own road, the estimate is 4.7. This does not line up with the true ATE because the estimate includes bias. Remember that bias is anything that takes us away from the truth.\n\n\nThe simple difference in outcomes (SDO) is an estimator for the ATE. It contains the ATE plus bias.\nCunningham (2020) very effectively shows how to decompose the simple difference estimator (SDO) into three parts: the ATE, selection bias, and heterogeneous treatment effect bias. Selection bias occurs when we are comparing unequal groups. Heterogeneous treatment effect bias occurs when a treatment (or exposure) has differential effects on units based on their characteristics.\nAs we will see in later chapters, randomization can be a very effective way to neutralize selection bias, but randomization is not always possible or maintained. Most research is non-experimental, or what many would call observational. Thus even if we assume that treatment effects are constant (effectively ignoring heterogeneous treatment effect bias), selection bias will remain a threat in many cases. Unfortunately for us, we can’t simply calculate it and subtract it away because the exact quantity is typically unknowable. That leaves us with with research design and statistical adjustment as our only defense. As Cunningham (2020) states:\n\nOne could argue that the entire enterprise of causal inference is about developing a reasonable strategy for negating the role that selection bias is playing in estimated causal effects.\n\n\n\n\nCAUSAL INFERENCE METHODS\n\n\n\n\n\nWatch Dr. Esther Duflo’s speech at the Nobel Banquet, 10 December 2019.\n\nThere are different causal inference methods for addressing selection bias, and which one a researcher chooses tends to be heavily influenced by their context and discipline. For instance, clinical researchers, biostatisticians, and behavioral interventionists often prefer to use experimental designs that randomly allocate people (or units) to different treatment arms.3 There is also a rich tradition of experimentation in the social sector among economists and public policy scholars. Economists Abhijit Banerjee, Esther Duflo, and Michael Kremer won the 2019 Nobel Prize in Economics4 for their experimental approach to alleviating global poverty.\nBut as I stated previously, many research questions in global health are not amenable to experimentation, and the approach to causal inference must be rooted in non-experimental (or observational) data. Matthay, Hagan, et al. (2020) divide these non-experimental approaches into two main buckets: confounder-control and instrument-based. Confounder-control is characterized by the use of statistical adjustment to make groups more comparable. You’ll find many examples of confounder-control in epidemiology and public health journals. Instrument-based studies, sometimes called quasi-experimental designs, estimate treatment effects by finding and leveraging arbitrary reasons why some people are more likely to be treated or exposed. Instrument-based studies are quite common in economics and psychology. I’ll introduce each approach in turn.\n\n\n\n\n\n\n\nAdditional causal inference frameworks\n\n\n\nBradford Hill’s Considerations. In 1965, Epidemiologist and statistician Sir Austin Bradford Hill proposed a set of nine domains to consider when evaluating the evidence for a causal relationship: (1) strength, (2) consistency, (3) specificity, (4) temporality, (5) biological gradient, (6) plausibility, (7) coherence, (8) experiment, and (9) analogy. It does not feature prominently in current debates about causal inference, and it’s commonly misapplied. Modern Epidemiology has a good summary and critique: ghr.link/mod.\nSufficient Cause Framework and Causal Pies. The sufficient-component cause model is an approach for conceptualizing cause and effect used largely for pedagogical purposes. Dr. Kenneth Rothman defined sufficient causes as the minimal set of conditions that produce a given outcome. This set of causes is often represented by pie charts."
  },
  {
    "objectID": "causalinference.html#causal-diagrams-and-confounder-control",
    "href": "causalinference.html#causal-diagrams-and-confounder-control",
    "title": "3  Causal Inference",
    "section": "3.2 Causal Diagrams and Confounder-Control",
    "text": "3.2 Causal Diagrams and Confounder-Control\nConfounding is a type of bias where variables 𝑋 and 𝑌 share a common cause 𝑍 that explains some or all of of the 𝑋𝑌 relationship. You’re likely familiar with examples of confounding like ice cream sales and violent crime. If you look just in the data, it looks like increases in ice cream sales could be causing increases in violent crime (or maybe vice versa), but this is what we call a spurious correlation. Ice cream sales and violent crime are both more common when the weather is warm. Once you statistically control for weather, let’s say by looking just at sales on hot days, there is no relationship between ice cream sales and crime.\nCausal relationships observed in non-experimental contexts are at high risk of confounding, and the goal of confounder-control studies is to find and statistically adjust for a sufficient set of variables to eliminate confounding. But this is not just an exercise in statistics because data are profoundly dumb (Pearl et al., 2018). A dataset cannot tell you which variables to adjust for, or what is a cause and what is an effect. For that you need information that lives outside of statistical models. You need causal models that are informed by domain expertise (McElreath, 2020).\n\nPearl, J. et al. (2018). The book of why: The new science of cause and effect (1st ed.). Basic Books, Inc.\n\n\n\n\n\nWatch Dr. Nick Huntington-Klein introduce causal diagrams.\n\nFor this reason, a graphical approach based on causal diagrams has emerged as a popular tool for causal inference in confounder-control studies (Pearl, 1995).5 The most common type of graphical model you’ll encounter is the causal directed acyclic graph, or DAG. Figure 3.4 shows an example DAG of the effect of taking the road less traveled on happiness.\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669–688.\n\n\n\n\nFigure 3.4: Causal directed acyclic graph (DAG) of the effect of taking the road less traveled on happiness.\n\n\n\n\nCAUSAL STORIES\n\n\n\nDr. Scott Cunningham’s book, Causal Inference: The Mixtape, is worth every penny. If you’re short on pennies, read it online for free.\n\nCunningham (2020) frames DAGs as storytelling devices. The story I am telling with this DAG is that the road traveled causes happiness directly and indirectly by creating new social relationships. This DAG also shows my assumption that happiness AND the decision to take the road less traveled are both caused in part by one’s cognitive style (e.g., sense of optimism); they share a common cause. Happiness is also caused by income which, like cognition, is a function of background characteristics like genetics and family.\n\nCunningham, S. (2020). Causal inference: The mixtape. Yale University Press.\n\n\n\n\n\n\n\nStart by drawing your assumptions\n\n\n\nBefore I even do anything with this DAG, or any DAG I create, I’ve accomplished a lot just by drawing my assumptions. The DAG represents my belief in the data generating process. It includes all nodes and connections that I believe are relevant to the effect of road traveled on happiness. I’ve made my assumptions clear and can proceed to identify how I will estimate the causal effect of interest.\nNow you might call bullshit, and that’s OK. You can draw a different DAG that might have different implications for the best analysis strategy. You and I should be able to defend our assumptions and be open to modifications based on subject matter criticism. But whether you draw a DAG or not, there is no escaping the need to make assumptions. DAGs just help to make your assumptions clear and transparent.\n\n\n\n\n\nCOMPONENTS OF A DAG\nAs a graph, DAGs consist of nodes and edges (or arrows). Nodes are variables like our exposure of interest, the road traveled, and our outcome of interest, happiness later in life. Nodes can take any form, from discrete values of road traveled (more traveled, less traveled) to continuous values of income. A DAG can include observed (measured) variables and unobserved variables, including background factors such as genetics.\n\n\n\n\n\nFigure 3.5: The same DAG again, reprinted for your convenience.\n\n\nNodes are connected by edges, directed arrows that make causal statements about how two variables are related. For instance, by drawing an arrow from road traveled to happiness, I’m asserting that the road one travels causes happiness. Arrows do not indicate whether this relationship is positive or negative, just that road traveled influences happiness. Equivalently, the absence of an arrow between nodes implies that there is no causal relationship.\nThe only hard rule in a DAG is that cycles are not permitted. Arrows can go into and out of a node, but there must not be any recursive pathways. For instance, social relationships ⟶ happiness ⟶ social relationships is not allowed. Causal effects must only flow forward in time. Spirals are allowed, however, and offer a way to represent that causal relationships between variables measured at different time points (e.g., social relationships_t1 ⟶ happiness_t2 ⟶ social relationships_t3 ⟶ happiness_t4).\nThere are three possible relationship structures in a DAG (McElreath, 2020):\n\nForks: In forks like road traveled ⟵ cognition ⟶ happiness, cognition is a common cause of the focal variables of interest. As such, cognition confounds the causal effect of road traveled on happiness; some (or all) of the observed association is due to cognition. When you see a fork, you should think confounding.\nPipes: Pipes (or chains) involve mediator variables like social relationships that represent an indirect causal chain of effects. For instance, road traveled causes new social relationships which causes happiness. Whether or not you are interested in the indirect causal effect depends on your research question.6\nColliders: Colliders (or inverted forks) are closed pathways like road traveled ⟶ active lifestyle ⟵ happiness where a node on the pathway only has incoming arrows. These pathways are closed by default and only open when conditioning on the collider, thereby distorting the relationship between road traveled and happiness.\n\nAs you will see shortly, being able to recognize these relationships will help you to identify your causal effect of interest.\n\n\n\n\n\n\n\nDescendants and ancestors\n\n\n\nGraphs like DAGs can also be described by the ancestry of the nodes. A descendant variable has at least one incoming arrow. Economists would call this an endogenous variable (vs an exogenous variable like background that has no incoming arrows). In the example DAG, happiness and social relationships are descendants of road traveled. Specifically, social relationships is a child of road traveled, and road traveled is its parent. Therefore, road traveled and social relationships are ancestors of happiness.\n\n\n\n\n\nDECIDE WHICH NODES TO INCLUDE IN A DAG\nIn order to use a DAG to identify a causal effect, you must include all of the relevant nodes and paths (Rohrer, 2018). As you can probably imagine, this can get out of hand quickly. Just look at the slide in Figure 3.6 that diagrams the American military’s perceived challenge in its war in Afghanistan.\n\nThis includes variables that you can measure and the ones you can’t (or didn’t) observe.\n\n\n\n\n\nFigure 3.6: War is hard. Source: U.S. Joint Chiefs of Staff. (Not a DAG, per se, but you get the point.)\n\n\n\n\n\n\nDr. Huntington-Klein’s book, The Effect: An Introduction to Research Design and Causality, should be on your bookshelf. If you’re not in a position to purchase it today, read it online for free.\n\nHuntington-Klein (2021) frames DAG creation as a balancing act:\n\nOn one hand, we want to omit from the diagram every variable and arrow we can possibly get away with. The simpler the diagram is, the easier it is to understand, and the more likely it is that we’ll be able to figure out how to identify the answer to our research question…On the other hand, omitting things makes the model simpler. But the real world is complex. So in our quest for simplicity, we might end up leaving out something that’s really important.\n\nA piece of practical advice is to draw a basic DAG and then add additional variables (nodes) only if you believe they causally affect two or more existing nodes in the DAG (Rohrer, 2018). For instance, maybe you could argue that being left handed also contributes to one’s decision to take the road less traveled. If handedness does not have an arrow into any other nodes, you can safely leave it out of the DAG.\n\nRohrer, J. M. (2018). Thinking clearly about correlations and causation: Graphical causal models for observational data. Advances in Methods and Practices in Psychological Science, 1(1), 27–42.\nIf this feels daunting, you’re doing it right. Science is hard, and I predict that you’ll find this process easier if you have the humility to know that, at best, your study will approximate the truth. There is a very good chance that your DAG will be wrong or incomplete. Your colleagues might tell you as much. This is part of the scientific process. Criticism should lead you to revise your DAG or strengthen how you defend your assumptions.\n\n\nTRACING ALL PATHS\nOnce you’ve drawn your DAG, the next step is to list all of the paths from the proposed cause to the outcome of interest. In this example, it means tracing all of the paths that go from road traveled to happiness.\nStart with road traveled and move your finger along each path until you get to another variable or to the outcome, happiness. When you encounter variables with arrows coming in or out, trace each path to the outcome. The direction of the arrows does not matter for tracing, just don’t trace back to variables you’ve already visited (in other words, no loops).\n\nroad traveled ⟶ happiness\nroad traveled ⟶ social relationships ⟶ happiness\nroad traveled ⟵ cognition ⟶ happiness\nroad traveled ⟵ cognition ⟵ background ⟶ income ⟶ happiness\nroad traveled ⟶ active ⟵ happiness\n\n\n\n\nView the example DAG or create your own at DAGitty.net.\n\nYou can check your work—or skip the manual tracing process entirely—by creating and analyzing your DAG in R. While you can manually enter your graph into R, a shortcut is to create your DAG visually in your browser at DAGitty.net and copy/paste the model code into R. The function paths() returns the same five paths we traced by hand.\n\nlibrary(dagitty)\n\ndag <- dagitty(\n'dag {\nbb=\"0,0,1,1\"\n\"road traveled\" [exposure,pos=\"0.224,0.452\"]\n\"social relationships\" [pos=\"0.355,0.547\"]\nactive [pos=\"0.359,0.677\"]\nbackground [pos=\"0.460,0.166\"]\ncognition [pos=\"0.355,0.340\"]\nhappiness [outcome,pos=\"0.501,0.449\"]\nincome [pos=\"0.505,0.285\"]\n\"road traveled\" -> \"social relationships\"\n\"road traveled\" -> active\n\"road traveled\" -> happiness\n\"social relationships\" -> happiness\nbackground -> cognition\nbackground -> income\ncognition -> \"road traveled\"\ncognition -> happiness\nhappiness -> active\nincome -> happiness\n}'\n)\n\npaths(dag)\n\n$paths\n[1] \"\\\"road traveled\\\" -> \\\"social relationships\\\" -> happiness\"         \n[2] \"\\\"road traveled\\\" -> active <- happiness\"                           \n[3] \"\\\"road traveled\\\" -> happiness\"                                     \n[4] \"\\\"road traveled\\\" <- cognition -> happiness\"                        \n[5] \"\\\"road traveled\\\" <- cognition <- background -> income -> happiness\"\n\n$open\n[1]  TRUE FALSE  TRUE  TRUE  TRUE\n\n\n\n\nEFFECT IDENTIFICATION\nNext we need to determine which paths are good and which are bad (Huntington-Klein, 2021). “Good paths” identify our research question. “Bad paths” are the alternate explanations for the causal effect that we need to close. In our example DAG, as in many DAGS, good paths often start with an arrow exiting the proposed cause and bad paths have arrows entering the proposed cause.\n\nAn exception would be if we are only interested in the direct effect of road traveled on happiness, we would label the mediation pathway through social relationships as a bad path and work to close it.\n\nFigure 3.7 visualizes the five paths in our example DAG and labels them good or bad. Notice that paths 1 and 2—the good paths—start with road traveled and flow forward to happiness. The rest are backdoor paths that we need to close.\n\n\n\n\nFigure 3.7: Good and bad paths in our example DAG.\n\n\n\n\n\n\nDr. Andrew Heiss has a great tutorial on ways to close backdoors through regression, inverse probability weighting, and matching.\n\nOpen backdoor paths bias the causal effect we want to estimate, so we need to close them. We can do this by conditioning on variables that confound the causal effect of interest through techniques like regression. The neat thing is that we do not necessarily need to control for every possible confounder, just a minimum set sufficient to close all backdoor paths.7 For instance, in Figure 3.7, you can see that adjusting for cognition in paths 3 and 4 is sufficient to close the open backdoor paths.\nPath 5 is also a backdoor path, but it’s closed by default because active is a collider (see the two incoming arrows). If we condition on active, let’s say by including it as a covariate in our regression, we will inadvertently open this path and introduce bias. There is such a thing as a bad covariate, and sometimes less is more when it comes to statistical models (McElreath, 2020; Westreich et al., 2013).8\n\nWestreich, D. et al. (2013). The table 2 fallacy: Presenting and interpreting confounder and modifier coefficients. American Journal of Epidemiology, 177(4), 292–298.\n\n\n\nThe logic of d-separation is rooted in Pearl’s do-calculus. Learn more in The Book of Why or this resource that Heiss created.\n\nIf this DAG is correct and complete, adjusting for (controlling for) cognition on the backdoor path makes the relationship between road traveled and happiness d-separated (direction separated) from all other nodes. In other words, the causal effect is said to be identified.\n\n\nEFFECT ESTIMATION\nThere are various statistical techniques to cut the bad paths so they don’t bias our causal effect of interest. I’ll show you regression. See Heiss (2020b) for other examples.\n\nHeiss, A. (2020b). Ways to close backdoors in DAGs.\n\nSimulation\nFor this example, I simulated a dataset on 1000 people who decided to take the road less traveled or the road more traveled.9 This is an observational dataset. There was no random assignment to road_traveled. The core variables include:\n\n\nSimulation is the only way to demonstrate that controlling for cognition recovers the correct effect. In real world datasets you don’t know the right answer. If you did, causal inference would be easy.\n\ncognition (confounding variable): A binary (0/1) variable set to 1 if the person scored high on a measure of optimism, otherwise 0. Imagine that everyone completed a questionnaire before they decided on a road. This questionnaire included items that assessed aspects of their cognitive style, and we used their answers to construct an indicator of high/low optimism.\nroad_traveled (exposure/treatment): A binary (0/1) variable set to 1 if the person chose the road less traveled, otherwise 0. This variable was simulated to be a function of cognition. In this dataset, the odds of taking the road less traveled are 18 times higher for high optimism folks.\nhappiness (outcome): A variable that can range from 0 to 10, where 10 represents greatest happiness. Imagine that data on happiness was collected 10 years after people selected and traveled down one of the roads. This variable was simulated to be a function of cognition and happiness. On average, high optimism folks scored 1 point higher on the measure of happiness.\nactive (collider): A binary (0/1) variable set to 1 if the person has an active lifestyle. Imagine that this variable was collected at sometime after the person traveled the road. This variable was simulated to be a function of road_traveled and happiness. active does not cause anything in the model.\n\n\n\n\nI simulated the data so that the road less traveled increases happiness by 1.5 points. That will be the correct answer going forward. Here are my receipts:\n\ndf_road_A %>% \n  summarize(mean = mean(happiness_road1-happiness_road0))\n\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1  1.50\n\n\n\n\nThe Problem: Confounding\n\n\n\n\n\nFigure 3.8: cognition confounds the 𝑋𝑌 relationship.\n\n\nFigure 3.8 should remind you that our core problem in this DAG is that the exposure (road_traveled) and the outcome (happiness) share a common cause: cognition. This is to say that cognition confounds the relationship between 𝑋 and 𝑌.\nYou can see this visually in Figure 3.9. In the left panel, people who scored high on optimism are represented in red (vs low in black). Notice that red appears more frequently among the road less traveled group AND red looks to be associated with higher happiness scores. If we just compare happiness scores by road traveled, we get the wrong answer (difference of 2.07). This is because cognition biases the 𝑋𝑌 relationship.\n\n\nRemember, we know the correct answer is 1.5 because that’s how I simulated the data generating process.\nTo get to the right answer, we need to hold cognition constant. In the right panel I show this by looking just at people with a low optimism score. Now if we compare happiness scores by road traveled, we get close to the correct answer (difference of 1.47).10\n\n\n\n\n\nFigure 3.9: Confounding\n\n\n\n\n\n\nA Solution: Multiple Regression\nIn practice we might estimate the effect via a technique like multiple regression, which I’ll show you here.11 You’ll see that I modified the variable names to make Figure 3.10 easier to read. Most notably, the exposure road traveled is represented as x and the outcome happiness is represented as y. Cognition and active are simply c and a, respectively.\nFigure 3.10 presents the results of three models:\n\ny ~ x: naive regression of happiness (y) on road_traveled (x)\ny ~ x + c: same as (1) but also controlling for cognition (c)\ny ~ x + c + a: same as (2) but also controlling for active (a)\n\n\n\n\n\n\nFigure 3.10: Multiple regression models\n\n\n\n\nThe red model y ~ x repeats the same mistake as above. It just estimates the impact of road traveled x on happiness y without accounting for the confounding role of cognition c. It returns the wrong answer.\nThe green model y ~ x + c controls for cognition c, thereby removing the parts of x and y that are explained by c (Heiss, 2020a). This closes the biasing pathway and returns the correct answer.\n\nHeiss, A. (2020a). Causal inference. In R for political data science (pp. 235–273). Chapman; Hall/CRC.\n\nThis should not be surprising. I simulated the data generating process with c confounding the relationship between x and y. Our DAG was therefore correct, and controlling for c recovers the simulated effect.\n\nThe blue model y ~ x + c + a gets us into trouble. In the data I simulated, active a is a collider. It doesn’t cause anything in the DAG, and the bad path it sits on is closed by default. When I control for it by adding it to the regression, I open the pathway and distort the relationship between x and y.\nIt might come as a surprise that something can go wrong by adding covariates to your model. Many of us are taught that it’s probably good or at least neutral to add all seemingly relevant variables to a regression. This is just bad advice. Some covariates will make your estimates worse, not better.\n\n\n\n\n\nWatch Dr. Richard McElreath’s excellent talk, Science Before Statistics: Causal Inference.\n\nMcElreath (2020) uses the term causal salad to describe this very common practice of tossing lots of “control” variables into a statistical model and telling a causal story. This approach can work when the goal is prediction, but it can go very very wrong when the goal is causal inference. One of his core points in Statistical Rethinking is that causal inference requires causal models that are separate from statistical models. Statistics alone can get us to the wrong answers. But if we follow the DAG—our causal model—we know to leave active alone.\n\n\n\nTHE BIG FINE PRINT\nDAGs are useful tools for causal inference, but they are not magic. If your DAG does not completely and correctly identify your causal effect of interest, your estimates will be biased. To make matters worse, there is no test that will tell you if you got it right or wrong.12\n\n\nA step I skipped for space is verifying conditional independencies. DAGitty.net and the {dagitty} R package will get you started.\n\nMcElreath, R. (2020). Statistical Rethinking: A Bayesian Course with Examples in R and Stan. CRC Press.\nBut let’s be clear: there is no approach to causal inference that sidesteps the need for unverifiable assumptions (McElreath, 2020). DAGs require you to make and defend your assumptions, but so does every other approach (you just might not know it)."
  },
  {
    "objectID": "causalinference.html#instrument-based-approaches-and-quasi-experimental-designs",
    "href": "causalinference.html#instrument-based-approaches-and-quasi-experimental-designs",
    "title": "3  Causal Inference",
    "section": "3.3 Instrument-Based Approaches and Quasi-Experimental Designs",
    "text": "3.3 Instrument-Based Approaches and Quasi-Experimental Designs\nIf confounder-control is about closing backdoors through statistical adjustment, instrument-based approaches are about isolating front doors (Huntington-Klein, 2021). These approaches are sometimes called quasi-experimental designs because they attempt to mimic the beauty and logic of a perfectly conducted randomized controlled trial (RCT).\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\nEXPERIMENTS DESTROY CONFOUNDING\nAs shown in Figure 3.11, RCTs (experiments), are effective because they close all backdoors that run from the proposed cause to the outcome. For instance, if we were somehow able to randomly assign people to the road less traveled or the road more traveled—and if people complied with these assignments—then the only arrow into road_traveled would be randomization. Randomization would be the only cause of road_traveled.\n\n\n\n\nFigure 3.11: Observational DAG vs experimental DAG.\n\n\n\nRandomization destroys confounding. This includes confounding from variables you think to measure, like cognition in this example, as well as variables that you can’t or don’t measure for whatever reason. This idea is so powerful that many people refer to experiments as the gold-standard when it comes to causal inference.13\n\n\nEXOGENOUS VARIATION WITHOUT RANDOMIZATION\nWhen randomization is not possible, confounding is likely. You can try to account for this confounding statistically (confounder control), or you can search for partial causes of the exposure/treatment that are unrelated to the outcome. Sometimes you can get lucky and find an exogenous source of variation in the exposure/treatment and use it to identify the causal effect.\nFor instance, imagine that we couldn’t randomize who travels which road, but we could restrict access to the road less traveled to people born on or after January 1, 1980. By this arbitrary rule, someone born on January 1, 1980 would be allowed to pass, but someone born on December 31, 1979 would have to take the road more traveled. This is the basic setup for a regression discontinuity design that fits in the instrument-based or quasi-experimental bucket (Figure 3.12).\n\n\n\n\nFigure 3.12: Regression discontinuity DAG.\n\n\n\nIn this design, birthdate ≥ 1980-01-01 is an instrument that causes exogenous variation in who is exposed to the road less traveled (see the left panel of Figure 3.13). This variation is almost as good as randomization because the cutoff is arbitrary. Furthermore, when we limit our investigation to people born right around this arbitrary cutoff, any potential link between birthdate and the outcome is broken. We’d argue that people born just before and just after the cutoff are similar in many observable and unobservable ways. The only difference is that people born before the cutoff weren’t allowed to take the road less traveled. This isolates the front door from road_traveled to happiness.\n\n\n\n\n\nFigure 3.13: A regression discontinuity example.\n\n\n\n\nThe key to this design, and others in this category, is that the instrument changes the probability of exposure (treatment) WITHOUT having any other mechanism of impacting the outcome (Matthay, Hagan, et al., 2020). In a later chapter we’ll see examples of regression discontinuity in practice, along with other quasi-experimental designs like instrumental variables, difference-in-differences, and interrupted time series."
  },
  {
    "objectID": "causalinference.html#key-assumptions-and-threats-to-internal-validity",
    "href": "causalinference.html#key-assumptions-and-threats-to-internal-validity",
    "title": "3  Causal Inference",
    "section": "3.4 Key Assumptions and Threats to Internal Validity",
    "text": "3.4 Key Assumptions and Threats to Internal Validity\nI listed three requirements for causal relationships when I defined causes:\n\ncauses must come before effects;\n\ncauses and effects are associated, meaning they go together or covary; and\nthere are no other plausible alternative explanations for the effect other than the proposed cause.\n\nThe third requirement—no other plausible alternative explanations—is the hardest of them all to meet. Every approach to causal inference relies on mostly untestable assumptions related to this requirement.\nA key assumption, no confounding, is known by different names across disciplines: ignorability of the treatment assignment (statistics), conditional independence (economics), and (conditional) exchangability (epidemiology) (Gelman et al., 2020). This assumption says that there is no relationship between the treatment (or exposure) someone receives and their potential outcomes. In observational studies, this assumption needs to hold after adjusting for any covariates. Matthay, Hagan, et al. (2020) gives the example of a violation of this assumption where people who are more likely to succeed across the board, regardless of treatment, are more likely to be treated. It would be like stacking the deck in favor of the treatment. Randomization destroys this confounding, but it’s a concern for observational studies. With confounder-control approaches in particular, you always have to worry about omitted variable bias—failing to adjust for the sufficient set of confounding variables.\n\nGelman, A. et al. (2020). Regression and other stories. Cambridge University Press.\n\nMatthay, E. C., Hagan, E., et al. (2020). Alternative causal inference methods in population health research: Evaluating tradeoffs and triangulating evidence. SSM Population Health, 10, 100526.\n\nNo measurement error is another assumption, but I’ll save that for the chapter on content validity.\n\nOnce you adjust for a set of covariates, you must think about the assumption of positivity. It says that all possible covariate subgroups in your study must have a non-zero chance of being exposed to the treatment. For instance, if your adjustment set includes biological sex, it would be a positivity violation if males could not receive the treatment. If you are not adjusting for sex, this is not a concern. Westreich (2019) gives the example of adjusting for biological sex in a study about the effects of hysterectomy when it’s only possible for people with a uterus to undergo a hysterectomy. The solution is simple: biological sex should not be a covariate in your adjustment set.\nAnother assumption is consistency (or treatment variance irrelevance). This is the idea that any variations in a treatment or exposure are irrelevant to the causal effect (Westreich, 2019). For instance, if the intervention under investigation is text message reminders to promote medication adherence, consistency is the assumption that variations in timing of message delivery (e.g., morning or night) are not important for the effect of reminders.\n\nWestreich, D. (2019). Epidemiology by Design: A Causal Approach to the Health Sciences. Oxford University Press, Incorporated.\n\nTHREATS TO INTERNAL VALIDITY\nThese causal inference assumptions will be likely familiar to anyone who uses the potential outcomes framework or Pearl’s graphical causal models approach, but folks with a psychology or education background might be more accustomed to identifying and avoiding threats to internal validity in the Campbell tradition (Shadish et al., 2002). You’ll recall from earlier in this chapter that internal validity pertains to the robustness of a causal claim that the observed variation in 𝑌 is caused by 𝑋. A study with a weak causal claim would be said to have low internal validity. Matthay & Glymour (2020) offer a helpful crosswalk between potential outcomes, DAGs, and the Campbell tradition, and West et al. (2010) compare Campbell’s approach with the potential outcomes approach (sometimes called the Rubin Causal Model).\n\nMatthay, E. C., & Glymour, M. M. (2020). A graphical catalog of threats to validity: Linking social science with epidemiology. Epidemiology, 31(3), 376.\n\nWest, S. G. et al. (2010). Campbell’s and rubin’s perspectives on causal inference. Psychological Methods, 15(1), 18.\n\n\n\nQuantitude Podcast, Episode 26, The Internal Validity Pre-Flight Checklist.\n\nIn the Campbell tradition, researchers are taught to identify the possible threats to internal validity, practice “control by design”, and strive for “coherent pattern matching”. In short, this means to think about the alternative plausible explanations for causal effects (threats), add design elements such as additional comparison groups to remove or reduce these threats (control by design), and make more complex hypotheses to raise the inferential bar and strengthen one’s causal claim (coherent pattern matching).\nPlausible alternative explanations for the causal effect are threats to internal validity. Shadish et al. (2002) enumerate eight specific threats and warn that threats can accumulate (see Table 3.1). The core threat is confounding, which Shadish et al. (2002) frame as a selection threat.\n\nShadish, W. R. et al. (2002). Experimental and quasi-experimental designs for generalized causal inference. Cengage Learning.\n\n\n\n\n\nTable 3.1:  Threats to internal validity from Shadish et al. (2002). \n \n  \n    Threat \n    Description \n  \n \n\n  \n    Ambiguous temporal precedence \n    Lack of clarity about which variable occurred first may yield confusion about which variable is the cause and which is the effect. \n  \n  \n    Selection \n    Systematic differences over conditions in respondent characteristics that could also cause the observed effect. \n  \n  \n    History \n    Events occurring concurrently with treatment could cause the observed effect. \n  \n  \n    Maturation \n    Naturally occurring changes over time could be confused with a treatment effect. \n  \n  \n    Regression artifact \n    When units are selected for their extreme scores, they will often have less extreme scores on other variables, an occurrence that can be confused with a treatment effect. \n  \n  \n    Attrition \n    Loss of respondents to treatment or to measurement can produce artifactual effects if that loss is systematically correlated with conditions. \n  \n  \n    Testing \n    Exposure to a test can affect test scores on subsequent exposures to that test, an occurrence that can be confused with a treatment effect. \n  \n  \n    Instrumentation \n    The nature of a measure may change over time or conditions in a way that could be confused with a treatment effect. \n  \n\n\n\n\n\n\nInternal validity is not a property of your research design per se; it’s a characteristic of your claim. While it’s true that some designs, like randomized controlled trials, face fewer threats to internal validity in theory, it’s also true that study implementation matters. The RCT label does not insulate a poorly conducted RCT from criticism. It’s best to think consider the internal validity of claims on a study-by-study basis. Also, there is not a statistical test that will tell you if your claim has high internal validity. You can use the results of various statistical tests to probe the support for your causal claim, but no test will tell you that a claim has high or low internal validity. P-values, for instance, are silent on the issue.\n\n\nViolations of assumptions like exchangability, positivity, and consistency threaten the internal validity of a claim, but the Campbell tradition does not use these terms."
  },
  {
    "objectID": "causalinference.html#coda-coffee-saves-lives",
    "href": "causalinference.html#coda-coffee-saves-lives",
    "title": "3  Causal Inference",
    "section": "3.5 Coda: Coffee Saves Lives?",
    "text": "3.5 Coda: Coffee Saves Lives?\nBefore we wrap-up this chapter, let’s return to the opening question: Does drinking a cup of coffee daily lower the risk of dying? Ding et al. (2015) suggested that the answer is yes. What do you think?\n\nDing, M. et al. (2015). Association of coffee consumption with total and cause-specific mortality in 3 large prospective cohorts. Circulation, 132(24), 2305–2315.\nThe authors took a confounder-control approach to the analysis, but they did not share a DAG. All of the variables in Figure 3.14 are covariates they mentioned adjusting for in their analysis. Is this the complete set of relevant variables? What are the backdoors that need closing? Are there any colliders?\n\n\n\n\nFigure 3.14: What’s in the DAG?\n\n\n\nCausal inference is hard, especially when dealing with observational data. We can’t rely on data or statistics alone to answer causal questions. In short, we need causal models."
  },
  {
    "objectID": "causalinference.html#keep-learning",
    "href": "causalinference.html#keep-learning",
    "title": "3  Causal Inference",
    "section": "3.6 Keep Learning",
    "text": "3.6 Keep Learning\n\nScott Cunningham’s “Causal Inference: The Mixtape”, ghr.link/cun\nNick Huntington-Klein’s “The Effect: An Introduction to Research Design and Causality”, ghr.link/eff\nRichard McElreath’s “Statistical Rethinking”, ghr.link/sre\nMorgan and Winship’s “Counterfactuals and Causal Inference: Methods and Principles for Social Research”, ghr.link/mor\nHernán and Robins’, “Causal Inference: What If”, ghr.link/wha\nDaniel Westreich’s, “Epidemiology by Design”, ghr.link/wes"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abimbola, S. et al. (2020). Will global health survive its\ndecolonisation? Lancet (London, England), 396(10263),\n1627–1628.\n\n\nBauer, M. S. et al. (2020). Implementation\nscience: What is it and why should I care?\nPsychiatry Research, 283, 112376.\n\n\nBennett, L. M. et al. (2018). Collaboration team science: Field\nguide. US Department of Health & Human Services, National\nInstitutes of Health.\n\n\nCampbell, D. T. (1969). Reforms as\nexperiments. American Psychologist, 24(4), 409.\n\n\nCampbell, W. C. (n.d.). Nobel\nlecture.\n\n\nCNN Wire. (2015). New\nstudy suggests coffee could literally be a lifesaver.\n\n\nCostello, A. et al. (2000). Moving to research partnerships in\ndeveloping countries. Bmj, 321(7264), 827–829.\n\n\nCronbach, L. J. (1982). Designing\nevaluations of educational and social programs. Jossey-Bass.\n\n\nCunningham, S. (2020). Causal\ninference: The mixtape. Yale University Press.\n\n\nDadonaite, B. (2019). Oral\nrehydration therapy: A low-tech solution that has saved millions of\nlives. In Our World in Data.\n\n\nDing, M. et al. (2015). Association of coffee consumption with total and\ncause-specific mortality in 3 large prospective cohorts.\nCirculation, 132(24), 2305–2315.\n\n\nFood and Drug Administration Amendments Act of 2007. (n.d.). Pub. L. No.\n110-85, 121 Stat. 904 (2007).\n\n\nGelman, A. et al. (2020). Regression and other stories.\nCambridge University Press.\n\n\nHaber, N. et al. (2018). Causal language and strength of inference in\nacademic and media articles shared in social media (CLAIMS): A\nsystematic review. PloS One, 13(5), e0196346.\n\n\nHeiss, A. (2020a). Causal inference. In R for political data\nscience (pp. 235–273). Chapman; Hall/CRC.\n\n\nHeiss, A. (2020b). Ways to close\nbackdoors in DAGs.\n\n\nHernán, M. A. (2018). The c-word: Scientific euphemisms do not improve\ncausal inference from observational data. American Journal of Public\nHealth, 108(5), 616–619.\n\n\nHirsch, L. A. (2021). Is it possible to decolonise global health\ninstitutions? Lancet, 397(10270), 189–190.\n\n\nHogan, M. C. et al. (2010). Maternal\nmortality for 181 countries, 1980–2008: A systematic analysis of\nprogress towards millennium development goal 5. The Lancet,\n375(9726), 1609–1623.\n\n\nHolland, P. W. (1986). Statistics and causal inference. Journal of\nthe American Statistical Association, 81(396), 945–960.\n\n\nHolst, J. (2020). Global health–emergence, hegemonic trends and\nbiomedical reductionism. Globalization and Health,\n16(1), 1–11.\n\n\nHuntington-Klein, N. (2021). The\neffect: An introduction to research design and causality.\nChapman; Hall/CRC.\n\n\nICMJE. (n.d.). Recommendations for the Conduct, Reporting, Editing, and\nPublication of Scholarly work in Medical Journals.\n\n\nIi, Y. B. et al. (2018). Advancing equitable\nglobal health research partnerships in Africa. BMJ\nGlobal Health, 3(4), e000868.\n\n\nIsrael, B. A. et al. (1998). Review of community-based research:\nAssessing partnership approaches to improve public health. Annual\nReview of Public Health, 19(1), 173–202.\n\n\nKing, G. et al. (2021). Designing\nSocial Inquiry: Scientific\nInference in Qualitative\nResearch, New Edition.\nPrinceton University Press.\n\n\nKoplan, J. P. et al. (2009). Towards a common definition of global\nhealth. The Lancet, 373(9679), 1993–1995.\n\n\nKruk, M. E. et al. (2016). Transforming Global\nHealth by Improving the Science\nof Scale-Up. PLOS Biology,\n14(3), e1002360.\n\n\nKyobutungi, C. et al. (2021). PLOS\nGlobal Public Health, charting a\nnew path towards equity, diversity and inclusion in global health.\nPLOS Global Public Health, 1(10), e0000038.\n\n\nLam, F. et al. (2019). A\nretrospective mixed-methods evaluation of a national ORS\nand zinc scale-up program in Uganda between 2011 and\n2016. Journal of Global Health, 9(1), 010504.\n\n\nLeary, M. (2012). Introduction to\nbehavioral research methods (6th ed.). Pearson.\n\n\nMacias Gil, R. et al. (2020). COVID-19 pandemic: Disparate health impact\non the hispanic/latinx population in the united states. The Journal\nof Infectious Diseases, 222(10), 1592–1595.\n\n\nMatthay, E. C., & Glymour, M. M. (2020). A graphical catalog of\nthreats to validity: Linking social science with epidemiology.\nEpidemiology, 31(3), 376.\n\n\nMatthay, E. C., Hagan, E., et al. (2020). Alternative causal inference\nmethods in population health research: Evaluating tradeoffs and\ntriangulating evidence. SSM Population Health, 10,\n100526.\n\n\nMcElreath, R. (2020). Statistical\nRethinking: A Bayesian\nCourse with Examples in R and\nStan. CRC Press.\n\n\nMerson, M. H. et al. (2018). Global health: Diseases, programs,\nsystems, and policies (4th ed.). Jones & Bartlett Learning.\n\n\nMicah, A. E. et al. (2021). Tracking\ndevelopment assistance for health and for COVID-19: A\nreview of development assistance, government, out-of-pocket, and other\nprivate spending on health for 204 countries and territories,\n1990–2050. The Lancet, 398(10308), 1317–1343.\n\n\nMorris, Z. S. et al. (2011). The answer is 17 years,\nwhat is the question: Understanding time lags in translational\nresearch. Journal of the Royal Society of Medicine,\n104(12), 510–520.\n\n\nNafilyan, V. et al. (2021). Occupation and\nCOVID-19 mortality in England: A national\nlinked data study of 14.3 million adults. medRxiv.\n\n\nPai, M. (n.d.). Decolonizing\nGlobal Health: A\nMoment To Reflect On\nA Movement. In Forbes.\n\n\nPearl, J. (1995). Causal diagrams for empirical research.\nBiometrika, 82(4), 669–688.\n\n\nPearl, J. et al. (2018). The book of why: The new science of cause\nand effect (1st ed.). Basic Books, Inc.\n\n\nPolicy Cures Research. (n.d.). G-FINDER data portal.\n\n\nPuffer, E. S. et al. (2013). Developing a family-based HIV prevention\nintervention in rural kenya: Challenges in conducting community-based\nparticipatory research. Journal of Empirical Research on Human\nResearch Ethics, 8(2), 119–128.\n\n\nRohrer, J. M. (2018). Thinking clearly about correlations and causation:\nGraphical causal models for observational data. Advances in Methods\nand Practices in Psychological Science, 1(1), 27–42.\n\n\nRossi, P. H. et al. (2003). Evaluation: A systematic\napproach. Sage Publications.\n\n\nRøttingen, J.-A. et al. (2013). Mapping of\navailable health research and development data: What’s there, what’s\nmissing, and what role is there for a global observatory? Lancet\n(London, England), 382(9900), 1286–1307.\n\n\nRoundtable, I. of M. (US). C. R. et al. (2002). Definitions of\nClinical Research and Components\nof the Enterprise. National Academies Press (US).\n\n\nRubin, D. B. (1974). Estimating causal effects of treatments in\nrandomized and nonrandomized studies. Journal of Educational\nPsychology, 66(5), 688.\n\n\nSatcher Health Leadership Institute. (2021). Health Equity\nTracker.\n\n\nShadish, W. R. et al. (2002). Experimental and quasi-experimental\ndesigns for generalized causal inference. Cengage Learning.\n\n\nSirleaf, E. J. et al. (2021). Achieving\nvaccination justice: A call for global cooperation.\nPLOS Global Public Health, 1(10), 1–3.\n\n\nSkolnik, R. (2019). Global health 101, fourth edition. Jones\n& Bartlett Learning.\n\n\nSridhar, D. (2012). Who\nSets the Global Health\nResearch Agenda? The\nChallenge of Multi-Bi\nFinancing. PLOS Medicine, 9(9),\ne1001312.\n\n\nWest, S. G. et al. (2010). Campbell’s and rubin’s perspectives on causal\ninference. Psychological Methods, 15(1), 18.\n\n\nWestreich, D. et al. (2013). The table 2 fallacy: Presenting and\ninterpreting confounder and modifier coefficients. American Journal\nof Epidemiology, 177(4), 292–298.\n\n\nWestreich, D. (2019). Epidemiology by\nDesign: A Causal\nApproach to the Health\nSciences. Oxford University Press, Incorporated.\n\n\nWHO. (n.d.). Investments on grants for biomedical research by\nfunder, type of grant, health category and recipient.\n\n\nWHO. (2013). Social\ndeterminants of health: Key concepts.\n\n\nWHO. (2020). Clinical\ntrials.\n\n\nWHO. (2021). Health\nEquity.\n\n\nWong, C. H. et al. (2019). Estimation of\nclinical trial success rates and related parameters.\nBiostatistics, 20(2), 273–286.\n\n\nWoolf, S. H. (2008). The\nMeaning of Translational Research\nand Why It Matters.\nJAMA, 299(2), 211–213."
  }
]